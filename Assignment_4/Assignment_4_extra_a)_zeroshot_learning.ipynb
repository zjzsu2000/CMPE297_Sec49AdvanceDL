{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "work",
      "language": "python",
      "name": "work"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Assignment_4_extra_a)_zeroshot learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_Sec49AdvanceDL/blob/master/Assignment_4/Assignment_4_extra_a)_zeroshot_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRr6OwcieAtS"
      },
      "source": [
        "**Extra points (optional) - will go to extra credit :\n",
        "\n",
        "a) Write colab to demo the use of pre trained multi model multi task learning model from ibm (refer to my slides - omninet). Demo zeroshot learning there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzYpcd47cTH_"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import scipy.io\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nn8wiQEd_sg",
        "outputId": "d25ca4ac-d694-4888-877e-60a62ec8ee5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SL3mK6ocTID"
      },
      "source": [
        "dataset = 'CUB'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIsoWpRPcTIJ"
      },
      "source": [
        "res101 = scipy.io.loadmat('/content/gdrive/dataset/xlsa17/data/'+dataset+'/res101.mat')\n",
        "att_splits = scipy.io.loadmat('/content/gdrive/dataset/xlsa17/data/'+dataset+'/att_splits.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVlRmlE5cTIN"
      },
      "source": [
        "res101.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Fr1-t1cTIS"
      },
      "source": [
        "att_splits.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq0yXtBNcTIb"
      },
      "source": [
        "trainval_loc = 'trainval_loc'\n",
        "train_loc = 'train_loc'\n",
        "val_loc = 'val_loc'\n",
        "test_loc = 'test_unseen_loc'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6nyJHOCcTIj"
      },
      "source": [
        "labels = res101['labels']\n",
        "labels_train = labels[np.squeeze(att_splits[train_loc]-1)]\n",
        "labels_val = labels[np.squeeze(att_splits[val_loc]-1)]\n",
        "labels_trainval = labels[np.squeeze(att_splits[trainval_loc]-1)]\n",
        "labels_test = labels[np.squeeze(att_splits[test_loc]-1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoyGloiMcTIo"
      },
      "source": [
        "labels_train[:10,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3lt2U9FcTIw"
      },
      "source": [
        "unique_labels = np.unique(labels)\n",
        "unique_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW2B248QcTI1"
      },
      "source": [
        "train_labels_seen = np.unique(labels_train)\n",
        "val_labels_unseen = np.unique(labels_val)\n",
        "trainval_labels_seen = np.unique(labels_trainval)\n",
        "test_labels_unseen = np.unique(labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_QY4bOocTI7"
      },
      "source": [
        "print(\"Number of overlapping classes between train and val:\",len(set(train_labels_seen).intersection(set(val_labels_unseen))))\n",
        "print(\"Number of overlapping classes between trainval and test:\",len(set(trainval_labels_seen).intersection(set(test_labels_unseen))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmBbP_XVcTJF"
      },
      "source": [
        "i = 0\n",
        "for labels in train_labels_seen:\n",
        "    labels_train[labels_train == labels] = i    \n",
        "    i = i+1\n",
        "j = 0\n",
        "for labels in val_labels_unseen:\n",
        "    labels_val[labels_val == labels] = j\n",
        "    j = j+1\n",
        "k = 0\n",
        "for labels in trainval_labels_seen:\n",
        "    labels_trainval[labels_trainval == labels] = k\n",
        "    k = k+1\n",
        "l = 0\n",
        "for labels in test_labels_unseen:\n",
        "    labels_test[labels_test == labels] = l\n",
        "    l = l+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXs9Ud7-cTJL"
      },
      "source": [
        "Let us denote the features X ∈ [d×m] available at training stage, where d is the dimensionality\n",
        "of the data, and m is the number of instances. We are useing resnet features which are extracted from `CUB` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r5CypJYcTJM"
      },
      "source": [
        "X_features = res101['features']\n",
        "train_vec = X_features[:,np.squeeze(att_splits[train_loc]-1)]\n",
        "val_vec = X_features[:,np.squeeze(att_splits[val_loc]-1)]\n",
        "trainval_vec = X_features[:,np.squeeze(att_splits[trainval_loc]-1)]\n",
        "test_vec = X_features[:,np.squeeze(att_splits[test_loc]-1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNJ0HpUhcTJR"
      },
      "source": [
        "print(\"Features for train:\", train_vec.shape)\n",
        "print(\"Features for val:\", val_vec.shape)\n",
        "print(\"Features for trainval:\", trainval_vec.shape)\n",
        "print(\"Features for test:\", test_vec.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKdCVr8IcTJV"
      },
      "source": [
        "#### Normalize the vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bde9OB53cTJX"
      },
      "source": [
        "def normalization(vec,mean,std):\n",
        "    sol = vec - mean\n",
        "    sol1 = sol/std\n",
        "    return sol1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6M-1CXEcTJf"
      },
      "source": [
        "#Signature matrix\n",
        "signature = att_splits['att']\n",
        "train_sig = signature[:,(train_labels_seen)-1]\n",
        "val_sig = signature[:,(val_labels_unseen)-1]\n",
        "trainval_sig = signature[:,(trainval_labels_seen)-1]\n",
        "test_sig = signature[:,(test_labels_unseen)-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LZUucdqcTJi"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        " Horse      Zebra\n",
        "[0.00354613 0.        ] Domestic_animal\n",
        "[0.13829921 0.20209503] 4_legged\n",
        "[0.06560347 0.04155225] carnivore\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VfEf5V8cTJi"
      },
      "source": [
        "print(train_sig[3:6,:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcrwLv7gcTJo"
      },
      "source": [
        "print(\"Signature for train:\", train_sig.shape)\n",
        "print(\"Signature for val:\", val_sig.shape)\n",
        "print(\"Signature for trainval:\", trainval_sig.shape)\n",
        "print(\"Signature for test:\", test_sig.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCI02LcRcTJs"
      },
      "source": [
        "#params for train and val set\n",
        "m_train = labels_train.shape[0]\n",
        "n_val = labels_val.shape[0]\n",
        "z_train = len(train_labels_seen)\n",
        "z1_val = len(val_labels_unseen)\n",
        "\n",
        "#params for trainval and test set\n",
        "m_trainval = labels_trainval.shape[0]\n",
        "n_test = labels_test.shape[0]\n",
        "z_trainval = len(trainval_labels_seen)\n",
        "z1_test = len(test_labels_unseen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G165OESncTJw"
      },
      "source": [
        "The ground truth is a one-hot encoded vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyZCIXfpcTJw"
      },
      "source": [
        "#ground truth for train and val set\n",
        "gt_train = 0*np.ones((m_train, z_train))\n",
        "gt_train[np.arange(m_train), np.squeeze(labels_train)] = 1\n",
        "\n",
        "#grountruth for trainval and test set\n",
        "gt_trainval = 0*np.ones((m_trainval, z_trainval))\n",
        "gt_trainval[np.arange(m_trainval), np.squeeze(labels_trainval)] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GWqprxIcTJ2"
      },
      "source": [
        "gt_train[:1,:100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF_xeG5BcTJ8"
      },
      "source": [
        "#train set\n",
        "d_train = train_vec.shape[0]\n",
        "a_train = train_sig.shape[0]\n",
        "\n",
        "#Weights\n",
        "V = np.zeros((d_train,a_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cv_cV6mtcTJ_"
      },
      "source": [
        "#trainval set\n",
        "d_trainval = trainval_vec.shape[0]\n",
        "a_trainval = trainval_sig.shape[0]\n",
        "W = np.zeros((d_trainval,a_trainval))\n",
        "\n",
        "#Note: These hyper-parameters were found using the code snippet available below\n",
        "gamm1 = 3\n",
        "alph1 = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG9iI1GCcTKE"
      },
      "source": [
        "The one-line code solution proposed.\n",
        "```\n",
        "V = inverse(XX' + γI) XYS' inverse(SS' + λI)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vvzWS9TcTKF"
      },
      "source": [
        "part_1_test = np.linalg.pinv(np.matmul(trainval_vec, trainval_vec.transpose()) + (10**alph1)*np.eye(d_trainval))\n",
        "part_0_test = np.matmul(np.matmul(trainval_vec,gt_trainval),trainval_sig.transpose())\n",
        "part_2_test = np.linalg.pinv(np.matmul(trainval_sig, trainval_sig.transpose()) + (10**gamm1)*np.eye(a_trainval))\n",
        "\n",
        "W = np.matmul(np.matmul(part_1_test,part_0_test),part_2_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzaj9IyYcTKK"
      },
      "source": [
        "For inference stage, \n",
        "```\n",
        "argmax(x'VS)\n",
        "```\n",
        "Where S is the signature matrix of the test_set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_s5bc4DcTKM"
      },
      "source": [
        "#predictions\n",
        "outputs_1 = np.matmul(np.matmul(test_vec.transpose(),W),test_sig)\n",
        "preds_1 = np.array([np.argmax(output) for output in outputs_1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw0bc-QVcTKP"
      },
      "source": [
        "cm = confusion_matrix(labels_test, preds_1)\n",
        "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "avg = sum(cm.diagonal())/len(test_labels_unseen)\n",
        "print(\"The top 1% accuracy is:\", avg*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiXkogQ7cTKS"
      },
      "source": [
        "accu = 0.10\n",
        "alph1 = 4\n",
        "gamm1 = 1\n",
        "for alpha in range(-3, 4):\n",
        "    for gamma in range(-3,4):\n",
        "        #One line solution\n",
        "        part_1 = np.linalg.pinv(np.matmul(train_vec, train_vec.transpose()) + (10**alpha)*np.eye(d_train))\n",
        "        part_0 = np.matmul(np.matmul(train_vec,gt_train),train_sig.transpose())\n",
        "        part_2 = np.linalg.pinv(np.matmul(train_sig, train_sig.transpose()) + (10**gamma)*np.eye(a_train))\n",
        "\n",
        "        V = np.matmul(np.matmul(part_1,part_0),part_2)\n",
        "        #print(V)\n",
        "\n",
        "        #predictions\n",
        "        outputs = np.matmul(np.matmul(val_vec.transpose(),V),val_sig)\n",
        "        preds = np.array([np.argmax(output) for output in outputs])\n",
        "\n",
        "        #print(accuracy_score(labels_val,preds))\n",
        "        cm = confusion_matrix(labels_val, preds)\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        avg = sum(cm.diagonal())/len(val_labels_unseen)\n",
        "        #print(\"Avg:\", avg, alpha, gamma)\n",
        "\n",
        "        if avg > accu:\n",
        "            accu = avg\n",
        "            alph1 = alpha\n",
        "            gamm1 = gamma\n",
        "print(alph1, gamm1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtgsLhDfcTKa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}