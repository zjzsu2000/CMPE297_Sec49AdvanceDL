{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Assignment_4_extra_d) implement_colab_keras_mmoe_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_Sec49AdvanceDL/blob/master/Assignment_4/Assignment_4_extra_d)_implement_colab_keras_mmoe_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl2F-kBklAkk"
      },
      "source": [
        "d) implement colab for keras mmoe demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ffr_n4dwkSk9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import tensordot, expand_dims\n",
        "from tensorflow.keras import layers, Model, initializers, regularizers, activations, constraints, Input\n",
        "\n",
        "from tensorflow.keras.backend import expand_dims, repeat_elements, sum\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpBJ4OhGkvW9",
        "outputId": "e11d097d-5aaf-40f9-9f67-5f1445a89013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Lizhen0797/MMoE-TF2.0.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MMoE-TF2.0'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 9 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtZvgryok5Zm",
        "outputId": "5d1e0e0a-a815-466a-b657-30474d9a15ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4-lHYoUkeb5"
      },
      "source": [
        "Refs:\n",
        "Paper Ma, Jiaqi , et al. \"Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts.\" the 24th ACM SIGKDD International Conference ACM, 2018.x Tensorflow 2.0 implement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMwFj7dkkSlD"
      },
      "source": [
        "class MMoE(tf.keras.Model):\n",
        "    def __init__(self, units, num_experts, num_tasks, \n",
        "                 use_expert_bias=True,use_gate_bias=True,expert_activation='relu', gate_activation='softmax',\n",
        "                 expert_bias_initializer='zeros',gate_bias_initializer='zeros',expert_bias_regularizer=None, \n",
        "                 gate_bias_regularizer=None, expert_bias_constraint=None,gate_bias_constraint=None,\n",
        "                 expert_kernel_initializer='VarianceScaling', gate_kernel_initializer='VarianceScaling',\n",
        "                 expert_kernel_regularizer=None,gate_kernel_regularizer=None,expert_kernel_constraint=None,\n",
        "                 gate_kernel_constraint=None,activity_regularizer=None, **kwargs):\n",
        "        super(MMoE, self).__init__(**kwargs)\n",
        "        \n",
        "        self.units = units\n",
        "        self.num_experts = num_experts\n",
        "        self.num_tasks = num_tasks\n",
        "        \n",
        "        # Weight parameter\n",
        "        self.expert_kernels = None\n",
        "        self.gate_kernels = None\n",
        "        self.expert_kernel_initializer = initializers.get(expert_kernel_initializer)\n",
        "        self.gate_kernel_initializer = initializers.get(gate_kernel_initializer)\n",
        "        self.expert_kernel_regularizer = regularizers.get(expert_kernel_regularizer)\n",
        "        self.gate_kernel_regularizer = regularizers.get(gate_kernel_regularizer)\n",
        "        self.expert_kernel_constraint = constraints.get(expert_kernel_constraint)\n",
        "        self.gate_kernel_constraint = constraints.get(gate_kernel_constraint)\n",
        "\n",
        "        # Activation parameter\n",
        "        #self.expert_activation = activations.get(expert_activation)\n",
        "        self.expert_activation = expert_activation\n",
        "        self.gate_activation = gate_activation\n",
        "\n",
        "        # Bias parameter\n",
        "        self.expert_bias = None\n",
        "        self.gate_bias = None\n",
        "        self.use_expert_bias = use_expert_bias\n",
        "        self.use_gate_bias = use_gate_bias\n",
        "        self.expert_bias_initializer = initializers.get(expert_bias_initializer)\n",
        "        self.gate_bias_initializer = initializers.get(gate_bias_initializer)\n",
        "        self.expert_bias_regularizer = regularizers.get(expert_bias_regularizer)\n",
        "        self.gate_bias_regularizer = regularizers.get(gate_bias_regularizer)\n",
        "        self.expert_bias_constraint = constraints.get(expert_bias_constraint)\n",
        "        self.gate_bias_constraint = constraints.get(gate_bias_constraint)\n",
        "\n",
        "        # Activity parameter\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        \n",
        "        self.expert_layers = []\n",
        "        self.gate_layers = []\n",
        "        \n",
        "        for i in range(self.num_experts):\n",
        "            self.expert_layers.append(layers.Dense(self.units, activation=self.expert_activation,\n",
        "                                                   use_bias=self.use_expert_bias,\n",
        "                                                   kernel_initializer=self.expert_kernel_initializer,\n",
        "                                                   bias_initializer=self.expert_bias_initializer,\n",
        "                                                   kernel_regularizer=self.expert_kernel_regularizer,\n",
        "                                                   bias_regularizer=self.expert_bias_regularizer,\n",
        "                                                   activity_regularizer=None,\n",
        "                                                   kernel_constraint=self.expert_kernel_constraint,\n",
        "                                                   bias_constraint=self.expert_bias_constraint))\n",
        "        for i in range(self.num_tasks):\n",
        "            self.gate_layers.append(layers.Dense(self.num_experts, activation=self.gate_activation,\n",
        "                                                 use_bias=self.use_gate_bias,\n",
        "                                                 kernel_initializer=self.gate_kernel_initializer,\n",
        "                                                 bias_initializer=self.gate_bias_initializer,\n",
        "                                                 kernel_regularizer=self.gate_kernel_regularizer,\n",
        "                                                 bias_regularizer=self.gate_bias_regularizer, activity_regularizer=None,\n",
        "                                                 kernel_constraint=self.gate_kernel_constraint,\n",
        "                                                 bias_constraint=self.gate_bias_constraint))\n",
        "    def call(self, inputs):\n",
        "        expert_outputs, gate_outputs, final_outputs = [], [], []\n",
        "        for expert_layer in self.expert_layers:\n",
        "            expert_output = expand_dims(expert_layer(inputs), axis=2)\n",
        "            #print(expert_output.shape)\n",
        "            expert_outputs.append(expert_output)\n",
        "        expert_outputs = tf.concat(expert_outputs,2)\n",
        "        #print(expert_outputs.shape)\n",
        "        \n",
        "        for gate_layer in self.gate_layers:\n",
        "            gate_outputs.append(gate_layer(inputs))\n",
        "            \n",
        "        for gate_output in gate_outputs:\n",
        "            #print('Gate Ouput')\n",
        "            #print(gate_output.shape)\n",
        "            expanded_gate_output = expand_dims(gate_output, axis=1)\n",
        "            #print(expanded_gate_output.shape)\n",
        "            weighted_expert_output = expert_outputs * repeat_elements(expanded_gate_output, self.units, axis=1)\n",
        "            #print(weighted_expert_output.shape)\n",
        "            final_outputs.append(sum(weighted_expert_output, axis=2))\n",
        "        return final_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK8plJ_SkSlI"
      },
      "source": [
        "input_layers = layers.Input(shape=(499,))\n",
        "mmoe_layer = MMoE(units=4, num_experts=8, num_tasks=2)(input_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg70f8g-kSlN"
      },
      "source": [
        "output_layers = []\n",
        "for index, task_layer in enumerate(mmoe_layer):\n",
        "    tower_layer = layers.Dense(units=8, activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling())(task_layer)\n",
        "    output_layer = layers.Dense(units=2, name=str(index), activation='softmax', kernel_initializer=tf.keras.initializers.VarianceScaling())(tower_layer)\n",
        "    output_layers.append(output_layer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDgsWvUnkSlS"
      },
      "source": [
        "model = tf.keras.Model(inputs=[input_layers], outputs=output_layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNTwH_UykSlW",
        "outputId": "2fa445f6-fd9b-4fe6-a231-0753d7afdbbb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 499)]             0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnmrWXbDkSlb",
        "outputId": "184c94a7-d56c-498f-b296-80d351220d46"
      },
      "source": [
        "input_layer = Input(shape=(499,))#[499,]\n",
        "\n",
        "\n",
        "    # Set up MMoE layer\n",
        "mmoe_layers = MMoE(units=4, num_experts=8, num_tasks=2)(input_layer)\n",
        "\n",
        "\n",
        "output_layers = []\n",
        "output_dict = {\n",
        "    '0':'income',\n",
        "    '1':'marital'\n",
        "}\n",
        "    # Build tower layer from MMoE layer\n",
        "for index, task_layer in enumerate(mmoe_layers):\n",
        "    tower_layer = layers.Dense(units=8, activation='relu', kernel_initializer=tf.keras.initializers.VarianceScaling())(task_layer)\n",
        "    output_layer = layers.Dense(units=2, name=output_dict[str(index)], activation='softmax',kernel_initializer=tf.keras.initializers.VarianceScaling())(tower_layer)\n",
        "    output_layers.append(output_layer)\n",
        "\n",
        "    # Compile model\n",
        "model = Model(inputs=[input_layer], outputs=output_layers)\n",
        "\n",
        "    # Print out model architecture summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 499)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "m_mo_e_22 (MMoE)                [(None, 4), (None, 4 24000       input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_231 (Dense)               (None, 8)            40          m_mo_e_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_232 (Dense)               (None, 8)            40          m_mo_e_22[0][1]                  \n",
            "__________________________________________________________________________________________________\n",
            "income (Dense)                  (None, 2)            18          dense_231[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "marital (Dense)                 (None, 2)            18          dense_232[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 24,116\n",
            "Trainable params: 24,116\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7Vim8vLkSlg"
      },
      "source": [
        "def csv_reader_dataset(filenames, n_readers=5, batch_size=32, n_parse_threads=5, shuffle_buffer_size=10000):\n",
        "    dataset = tf.data.Dataset.list_files(filenames)\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filename : tf.data.TextLineDataset(filename),\n",
        "        cycle_length=n_readers\n",
        "    )\n",
        "    dataset.shuffle(shuffle_buffer_size)\n",
        "    dataset = dataset.map(parse_csv_line, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzXVoQk8kSlj"
      },
      "source": [
        "def parse_csv_line(line, n_feature=503):\n",
        "    defs = [tf.constant(np.nan)] * n_feature\n",
        "    parsed_field = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(parsed_field[0:-4])\n",
        "    y_income = tf.stack(parsed_field[-4:-2])\n",
        "    y_marital = tf.stack(parsed_field[-2:])\n",
        "    return x, (y_income, y_marital)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL1odHVRkSlm"
      },
      "source": [
        "def get_filename_by_prefix(source_dir,prefix_name):\n",
        "    all_files = os.listdir(source_dir)\n",
        "    results = []\n",
        "    for filename in all_files:\n",
        "        if filename.startswith(prefix_name):\n",
        "            results.append(os.path.join(source_dir, filename))\n",
        "    return results\n",
        "source_dir='/Users/lizhen/Code/data_set/census-income/generate_csv/'\n",
        "train_filenames = get_filename_by_prefix(source_dir, 'train')\n",
        "valid_filenames = get_filename_by_prefix(source_dir, 'val')\n",
        "test_filenames = get_filename_by_prefix(source_dir, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xSeM2AZkSlq"
      },
      "source": [
        "metrics = [\n",
        "            tf.keras.metrics.TruePositives(name='tp'),\n",
        "            tf.keras.metrics.FalsePositives(name='fp'),\n",
        "            tf.keras.metrics.TrueNegatives(name='tn'),\n",
        "            tf.keras.metrics.FalseNegatives(name='fn'),\n",
        "            tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "            tf.keras.metrics.Precision(name='precision'),\n",
        "            tf.keras.metrics.Recall(name='recall'),\n",
        "            tf.keras.metrics.AUC(name='auc'),\n",
        "            tf.keras.metrics.AUC(name='prauc',curve='PR')\n",
        "        ]\n",
        "model.compile(\n",
        "    loss={'income':'binary_crossentropy','marital':'binary_crossentropy'},\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=metrics,\n",
        "    experimental_run_tf_function=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t0O7J1ZkSlu"
      },
      "source": [
        "train_dataset = csv_reader_dataset(train_filenames)\n",
        "val_dataset = csv_reader_dataset(valid_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "234IlsFpkSlw"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWuaG6-ZkSly",
        "outputId": "6d5b1436-26ce-4153-862c-bab71a0294a5"
      },
      "source": [
        "model.fit(train_dataset, validation_data=val_dataset, epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6236/6236 [==============================] - 241s 39ms/step - loss: 0.5481 - income_loss: 0.3852 - marital_loss: 0.1629 - income_tp: 187161.0000 - income_fp: 12362.0000 - income_tn: 187161.0000 - income_fn: 12362.0000 - income_accuracy: 0.9380 - income_precision: 0.9380 - income_recall: 0.9380 - income_auc: 0.9384 - income_prauc: 0.9152 - marital_tp: 187294.0000 - marital_fp: 12229.0000 - marital_tn: 187294.0000 - marital_fn: 12229.0000 - marital_accuracy: 0.9387 - marital_precision: 0.9387 - marital_recall: 0.9387 - marital_auc: 0.9851 - marital_prauc: 0.9848 - val_loss: 0.0000e+00 - val_income_loss: 0.0000e+00 - val_marital_loss: 0.0000e+00 - val_income_tp: 0.0000e+00 - val_income_fp: 0.0000e+00 - val_income_tn: 0.0000e+00 - val_income_fn: 0.0000e+00 - val_income_accuracy: 0.0000e+00 - val_income_precision: 0.0000e+00 - val_income_recall: 0.0000e+00 - val_income_auc: 0.0000e+00 - val_income_prauc: 0.0000e+00 - val_marital_tp: 0.0000e+00 - val_marital_fp: 0.0000e+00 - val_marital_tn: 0.0000e+00 - val_marital_fn: 0.0000e+00 - val_marital_accuracy: 0.0000e+00 - val_marital_precision: 0.0000e+00 - val_marital_recall: 0.0000e+00 - val_marital_auc: 0.0000e+00 - val_marital_prauc: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x6690d4690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnYSMUoykSl1",
        "outputId": "88c105ac-42ae-4343-9d38-c27251975105"
      },
      "source": [
        "for x,y in val_dataset.take(1):\n",
        "    print(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[  4.   0.   0. ...   1.   0.   0.]\n",
            " [ 39. 500.   0. ...   1.   0.   0.]\n",
            " [ 29.   0.   0. ...   1.   0.   0.]\n",
            " ...\n",
            " [ 28.   0.   0. ...   1.   0.   0.]\n",
            " [ 17.   0.   0. ...   1.   0.   0.]\n",
            " [ 34.   0.   0. ...   1.   0.   0.]], shape=(32, 499), dtype=float32) (<tf.Tensor: id=46621, shape=(32, 2), dtype=float32, numpy=\n",
            "array([[1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.]], dtype=float32)>, <tf.Tensor: id=46622, shape=(32, 2), dtype=float32, numpy=\n",
            "array([[0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [0., 1.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.],\n",
            "       [1., 0.],\n",
            "       [0., 1.],\n",
            "       [1., 0.]], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2fLEgfekSl6"
      },
      "source": [
        "test_dataset = csv_reader_dataset(test_filenames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9GN9UfckSl_",
        "outputId": "648c1cf6-81a7-40af-dd95-5ae4b57603dd"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   1559/Unknown - 42s 27ms/step - loss: 0.5820 - income_loss: 0.3672 - marital_loss: 0.2148 - income_tp: 46799.0000 - income_fp: 3082.0000 - income_tn: 46799.0000 - income_fn: 3082.0000 - income_accuracy: 0.9382 - income_precision: 0.9382 - income_recall: 0.9382 - income_auc: 0.9410 - income_prauc: 0.9255 - marital_tp: 45783.0000 - marital_fp: 4098.0000 - marital_tn: 45783.0000 - marital_fn: 4098.0000 - marital_accuracy: 0.9178 - marital_precision: 0.9178 - marital_recall: 0.9178 - marital_auc: 0.9737 - marital_prauc: 0.9729"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5820121931161844,\n",
              " 0.36719403,\n",
              " 0.2148183,\n",
              " 46799.0,\n",
              " 3082.0,\n",
              " 46799.0,\n",
              " 3082.0,\n",
              " 0.93821293,\n",
              " 0.93821293,\n",
              " 0.93821293,\n",
              " 0.94098943,\n",
              " 0.9255163,\n",
              " 45783.0,\n",
              " 4098.0,\n",
              " 45783.0,\n",
              " 4098.0,\n",
              " 0.9178445,\n",
              " 0.9178445,\n",
              " 0.9178445,\n",
              " 0.97368747,\n",
              " 0.9729181]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKcIpzCbkSmH",
        "outputId": "0d82919b-d6d3-4ecf-c044-b12748f097bf"
      },
      "source": [
        "test_filenames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_09.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_08.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_06.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_07.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_05.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_04.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_00.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_01.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_03.csv',\n",
              " '/Users/lizhen/Code/data_set/census-income/generate_csv/test_data_02.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2hPUd7mkSmM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}