{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Assignment_1_ Part_2_semi-supervised.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "tAd20_mdkO9Z",
        "v7B6sJaYkO9f"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_Sec49AdvanceDL/blob/master/Assignment_1/Assignment_1_%20Part_2/semi_supervised_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUNnjaJ4kO86",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Assignment_1_ Part_2:Semisupervised Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMd7BeLojKEr",
        "colab_type": "text"
      },
      "source": [
        "Jacky Chow (Jie Zou) ID:014545284\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1U1Wewlk67z",
        "colab_type": "text"
      },
      "source": [
        "##Semi-supervised learning \n",
        "\n",
        "supervised learning training data very few labeled examples & large number of unlabeled examples.\n",
        "\n",
        "- unlabelled data may require use/inspiration unsupervised methods (clustering and density estimation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJGmDAq8lEHr",
        "colab_type": "text"
      },
      "source": [
        "##Target \n",
        "\n",
        "In this colab, I will illustrate how Semi-supervised learning works through a simple example based on the credit_card_data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe1qXqPckO87",
        "colab_type": "text"
      },
      "source": [
        "## Lib import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X-jOrK4kO88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "19d4953f-2474-443f-95ab-334da307a80d"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, time, re\n",
        "import pickle, gzip\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "color = sns.color_palette()\n",
        "import matplotlib as mpl\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from sklearn import preprocessing as pp\n",
        "from sklearn.model_selection import train_test_split as tts \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "\n",
        "import lightgbm as lgb\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "K = keras.backend\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Input, Lambda\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.losses import mse, binary_crossentropy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99n0SMUkO9A",
        "colab_type": "text"
      },
      "source": [
        "### Check\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWNy7opZkO9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "29a2309c-de5a-49ca-f543-541f5158a583"
      },
      "source": [
        "import sys, sklearn\n",
        "print(f'sklearn    {sklearn.__version__}')\n",
        "print(f'tensorflow {tf.__version__}')\n",
        "print(f'keras      {keras.__version__}')\n",
        "print(f'numpy      {np.__version__}')\n",
        "print(f'lightgbp   {lgb.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sklearn    0.22.2.post1\n",
            "tensorflow 2.3.0\n",
            "keras      2.4.0\n",
            "numpy      1.18.5\n",
            "lightgbp   2.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUVVLLKLkO9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7dZOVKckO9H",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zrTbaQekO9I",
        "colab_type": "text"
      },
      "source": [
        "### Load the data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG1sc7g7kemu",
        "colab_type": "text"
      },
      "source": [
        "https://www.kaggle.com/mlg-ulb/creditcardfraud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgwP1BbLkO9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the data \n",
        "current_path = os.getcwd()\n",
        "filePath = os.path.sep.join(['', 'datasets', 'credit_card_data', 'credit_card.csv'])\n",
        "data = pd.read_csv(current_path + filePath)\n",
        "\n",
        "dataX = data.copy().drop(['Class','Time'],axis=1)\n",
        "dataY = data['Class'].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgP-ytkrkO9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp4O65gWkO9P",
        "colab_type": "text"
      },
      "source": [
        "### Scale the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a74eXHVpkO9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresToScale = dataX.columns\n",
        "sX = pp.StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "dataX.loc[:,featuresToScale] = sX.fit_transform(dataX[featuresToScale])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIuXY-jIkO9S",
        "colab_type": "text"
      },
      "source": [
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_HFmV7bkO9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = tts(dataX, dataY, test_size=0.33, \n",
        "                                       random_state=2018, stratify=dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l04FWoqRkO9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print([x.shape for x in (X_train, X_test, y_train, y_test)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUDLJJ37kO9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(y_train==0),np.sum(y_train==1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAd20_mdkO9Z",
        "colab_type": "text"
      },
      "source": [
        "### Drop the labels from the training set to get some unlable data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_k_f7DOkO9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toDrop = y_train[y_train==1].sample(frac=0.90,random_state=2018)\n",
        "X_train.drop(labels=toDrop.index,inplace=True)\n",
        "y_train.drop(labels=toDrop.index,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNQKuBL6kO9c",
        "colab_type": "text"
      },
      "source": [
        "Check the number of fruadulant cases left after dropping 90% of the cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoBqTtwHkO9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(y_train==0),np.sum(y_train==1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7B6sJaYkO9f",
        "colab_type": "text"
      },
      "source": [
        "### Define evaluation function and plotting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grt1mObzkO9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def a_scores(originalDF, reducedDF):\n",
        "    loss = np.sum((np.array(originalDF) - \n",
        "                   np.array(reducedDF))**2, axis=1)\n",
        "    loss = pd.Series(data=loss,index=originalDF.index)\n",
        "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lj21hV7kO9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_results(trueLabels, anomalyScores, returnPreds = False):\n",
        "    preds = pd.concat([trueLabels, anomalyScores], axis=1)\n",
        "    preds.columns = ['trueLabel', 'anomalyScore']\n",
        "    precision, recall, thresholds = \\\n",
        "        precision_recall_curve(preds['trueLabel'], \n",
        "                               preds['anomalyScore'])\n",
        "    average_precision = average_precision_score( \n",
        "                        preds['trueLabel'], preds['anomalyScore'])\n",
        "    \n",
        "    plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
        "    plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    \n",
        "    plt.title('Precision-Recall curve: Average Precision = \\\n",
        "        {0:0.2f}'.format(average_precision))\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(preds['trueLabel'], \n",
        "                                     preds['anomalyScore'])\n",
        "    areaUnderROC = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
        "    plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic: Area under the \\\n",
        "        curve = {0:0.2f}'.format(areaUnderROC))\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    \n",
        "    if returnPreds==True:\n",
        "        return preds, average_precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukjl9M3ukO9k",
        "colab_type": "text"
      },
      "source": [
        "Define a new function to assess precision at a given recall threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRdqYO_lkO9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def precisionAnalysis(df, column, threshold):\n",
        "    df.sort_values(by=column, ascending=False, inplace=True)\n",
        "    threshold_value = threshold*df.trueLabel.sum()\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i < threshold_value+1:\n",
        "        if df.iloc[j][\"trueLabel\"]==1:\n",
        "            i += 1\n",
        "        j += 1\n",
        "    return df, i/j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zD6GaS2kO9n",
        "colab_type": "text"
      },
      "source": [
        "## Supervised Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ1Bow0dkO9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_fold = StratifiedKFold(n_splits=5,shuffle=True,random_state=2018)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppWbCBffkO9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_lightGB = {\n",
        "    'task': 'train',\n",
        "    'application':'binary',\n",
        "    'num_class':1,\n",
        "    'boosting': 'gbdt',\n",
        "    'objective': 'binary',\n",
        "    'metric': 'binary_logloss',\n",
        "    'metric_freq':50,\n",
        "    'is_training_metric':False,\n",
        "    'max_depth':4,\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.01,\n",
        "    'feature_fraction': 1.0,\n",
        "    'bagging_fraction': 1.0,\n",
        "    'bagging_freq': 0,\n",
        "    'bagging_seed': 2018,\n",
        "    'verbose': 0,\n",
        "    'num_threads':16\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_QJPzd-kO9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingScores = []\n",
        "cvScores = []\n",
        "predictionsBasedOnKFolds = pd.DataFrame(data=[], index=y_train.index, \n",
        "                                        columns=['prediction'])\n",
        "\n",
        "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), \n",
        "                                          y_train.ravel()):\n",
        "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], X_train.iloc[cv_index,:]\n",
        "    y_train_fold, y_cv_fold = y_train.iloc[train_index],   y_train.iloc[cv_index]\n",
        "    \n",
        "    lgb_train = lgb.Dataset(X_train_fold, y_train_fold)\n",
        "    lgb_eval = lgb.Dataset(X_cv_fold, y_cv_fold, reference=lgb_train)\n",
        "    gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=2000,\n",
        "                   valid_sets=lgb_eval, early_stopping_rounds=200)\n",
        "    \n",
        "    loglossTraining = log_loss(y_train_fold, gbm.predict(X_train_fold, \n",
        "                                num_iteration=gbm.best_iteration))\n",
        "    trainingScores.append(loglossTraining)\n",
        "    \n",
        "    predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'] = gbm.predict(\n",
        "        X_cv_fold, num_iteration=gbm.best_iteration) \n",
        "    loglossCV = log_loss(y_cv_fold, predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'])\n",
        "    cvScores.append(loglossCV)\n",
        "    \n",
        "    print(f'Training Log Loss: {loglossTraining}')\n",
        "    print(f'CV Log Loss: {loglossCV}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2oIiGl5kO9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loglossLightGBMGradientBoosting = log_loss(y_train, \n",
        "        predictionsBasedOnKFolds.loc[:,'prediction'])\n",
        "print(f'LightGBM Gradient Boosting Log Loss: {round(loglossLightGBMGradientBoosting,4)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HA9rfJCkO9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, average_precision = plotResults(y_train, \n",
        "                        predictionsBasedOnKFolds.loc[:,'prediction'], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdd4AFVpkO9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = pd.Series(data=gbm.predict(X_test, \n",
        "                num_iteration=gbm.best_iteration), index=X_test.index)\n",
        "preds, average_precision = plotResults(y_test, predictions, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYKziUHLkO91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, precision = precisionAnalysis(preds, \"anomalyScore\", 0.75)\n",
        "print(f'Precision at 75% recall {round(precision,4)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yriuXuI5kO92",
        "colab_type": "text"
      },
      "source": [
        "## Unsupervised Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84fdXpCFkO93",
        "colab_type": "text"
      },
      "source": [
        "Take the 33 fraudulent cases, duplicate these 100 times and then append them to the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6fhiNtSkO93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oversample_multiplier = 100\n",
        "\n",
        "X_train_original = X_train.copy()\n",
        "y_train_original = y_train.copy()\n",
        "X_test_original = X_test.copy()\n",
        "y_test_original = y_test.copy()\n",
        "\n",
        "X_train_oversampled = X_train.copy()\n",
        "y_train_oversampled = y_train.copy()\n",
        "X_train_oversampled = X_train_oversampled.append( \\\n",
        "        [X_train_oversampled[y_train==1]]*oversample_multiplier, \\\n",
        "        ignore_index=False)\n",
        "y_train_oversampled = y_train_oversampled.append( \\\n",
        "        [y_train_oversampled[y_train==1]]*oversample_multiplier, \\\n",
        "        ignore_index=False)\n",
        "\n",
        "X_train = X_train_oversampled.copy()\n",
        "y_train = y_train_oversampled.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKgp8ahwkO97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqUxMFqQkO9_",
        "colab_type": "text"
      },
      "source": [
        "A sparse two-layer overcomplete autoencoder with a linear a linear activation function.  \n",
        "Forty nodes in the hidden layer and a dropout of 2%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En-XFgTSkO9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(units=40, activation='linear', activity_regularizer=regularizers.l1(1e-4),\n",
        "                input_dim=29, name='hidden_layer'))\n",
        "model.add(Dropout(0.02))\n",
        "model.add(Dense(units=29, activation='linear'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyGkasK4kO-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K714drv8kO-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs =  5\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(x=X_train, y=X_train, epochs=num_epochs, batch_size=batch_size, shuffle=True,\n",
        "                    validation_split=0.20, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTsnRi4VkO-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictionsTrain = model.predict(X_train_original, verbose=1)\n",
        "anomalyScoresAETrain = anomalyScores(X_train_original, predictionsTrain)\n",
        "preds, average_precision = plotResults(y_train_original, anomalyScoresAETrain, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lRijpkLkO-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test, verbose=1)\n",
        "anomalyScoresAE = anomalyScores(X_test, predictions)\n",
        "preds, average_precision = plotResults(y_test, anomalyScoresAE, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNNZRZRNkO-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, precision = precisionAnalysis(preds, \"anomalyScore\", 0.75)\n",
        "print(f'Precision at 75% recall {round(precision,4)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1dWWjyxkO-N",
        "colab_type": "text"
      },
      "source": [
        "## Semisupervised Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw6cQL6ckO-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_name = 'hidden_layer'\n",
        "\n",
        "intermediate_layer_model  = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
        "intermediate_output_train = intermediate_layer_model.predict(X_train_original)\n",
        "intermediate_output_test  = intermediate_layer_model.predict(X_test_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djaNyEdtkO-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_output_trainDF = pd.DataFrame(data=intermediate_output_train,index=X_train_original.index)\n",
        "intermediate_output_testDF  = pd.DataFrame(data=intermediate_output_test,index=X_test_original.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFG9R9kkkO-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train_original.merge(intermediate_output_trainDF, left_index=True,right_index=True)\n",
        "X_test  = X_test_original.merge(intermediate_output_testDF, left_index=True,right_index=True)\n",
        "y_train = y_train_original.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K29jIRxKkO-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingScores = []\n",
        "cvScores = []\n",
        "predictionsBasedOnKFolds = pd.DataFrame(data=[],index=y_train.index,  columns=['prediction'])\n",
        "\n",
        "for train_index, cv_index in k_fold.split(np.zeros(len(X_train)), y_train.ravel()):\n",
        "    X_train_fold, X_cv_fold = X_train.iloc[train_index,:], X_train.iloc[cv_index,:]\n",
        "    y_train_fold, y_cv_fold = y_train.iloc[train_index], y_train.iloc[cv_index]\n",
        "    \n",
        "    lgb_train = lgb.Dataset(X_train_fold, y_train_fold)\n",
        "    lgb_eval = lgb.Dataset(X_cv_fold, y_cv_fold, reference=lgb_train)\n",
        "    gbm = lgb.train(params_lightGB, lgb_train, num_boost_round=5000,\n",
        "                   valid_sets=lgb_eval, early_stopping_rounds=200)\n",
        "    \n",
        "    loglossTraining = log_loss(y_train_fold, gbm.predict(X_train_fold,num_iteration=gbm.best_iteration))\n",
        "    trainingScores.append(loglossTraining)\n",
        "    \n",
        "    predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'] = gbm.predict(X_cv_fold, num_iteration=gbm.best_iteration) \n",
        "    loglossCV = log_loss(y_cv_fold, predictionsBasedOnKFolds.loc[X_cv_fold.index,'prediction'])\n",
        "    cvScores.append(loglossCV)\n",
        "    \n",
        "    print(f'Training Log Loss: {round(loglossTraining,4)}')\n",
        "    print(f'CV Log Loss: {round(loglossCV,4)}' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAT31QLvkO-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loglossLightGBMGradientBoosting = log_loss(y_train, predictionsBasedOnKFolds.loc[:,'prediction'])\n",
        "print(f'LightGBM Gradient Boosting Log Loss: {round(loglossLightGBMGradientBoosting,4)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2-V4wokkO-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, average_precision = plotResults(y_train, predictionsBasedOnKFolds.loc[:,'prediction'], True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caXk3oQ1kO-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = pd.Series(data=gbm.predict(X_test, num_iteration=gbm.best_iteration),index=X_test.index)\n",
        "preds, average_precision = plotResults(y_test, predictions, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N3PJjXlkO-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds, precision = precisionAnalysis(preds, \"anomalyScore\", 0.75)\n",
        "print(f'{round(precision,4)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiQ-oOX_kO-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featuresImportance = pd.DataFrame(data=list(gbm.feature_importance()), index=X_train.columns,columns=['featImportance'])\n",
        "featuresImportance = featuresImportance/featuresImportance.sum()\n",
        "featuresImportance.sort_values(by='featImportance', ascending=False,inplace=True)\n",
        "featuresImportance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq3XaKHukO-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}