{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extra_credit_assignment5_b)_pretrained_word_embeddings",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_Sec49AdvanceDL/blob/master/Assignment_5/Extra_credit_assignment5_b)_pretrained_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmWlcyagdbR9"
      },
      "source": [
        "# b) Text classification with pretrained word embeddings (GLOve)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRONgRk_dbR9"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXIfPW3BdbR9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yop51R-bdbR9"
      },
      "source": [
        "\n",
        "http://nlp.stanford.edu/projects/glove/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1Lkg8RsdbR9"
      },
      "source": [
        "## Download the Newsgroup20 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL-cHpYRdbR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e7b045-249d-4ba3-eb6d-7c6b8d341e40"
      },
      "source": [
        "data_path = keras.utils.get_file(\n",
        "    \"news20.tar.gz\",\n",
        "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
        "    untar=True,\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
            "17334272/17329808 [==============================] - 10s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubuIX9hIdbR9"
      },
      "source": [
        "## Data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKBVaNv1dbR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2318c15-f06d-4b2e-fb9f-9c724d8ba553"
      },
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
        "dirnames = os.listdir(data_dir)\n",
        "print(\"Number of directories:\", len(dirnames))\n",
        "print(\"Directory names:\", dirnames)\n",
        "\n",
        "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
        "print(\"Number of files in comp.graphics:\", len(fnames))\n",
        "print(\"Some example filenames:\", fnames[:5])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of directories: 20\n",
            "Directory names: ['talk.politics.guns', 'misc.forsale', 'sci.space', 'rec.motorcycles', 'comp.sys.ibm.pc.hardware', 'soc.religion.christian', 'comp.sys.mac.hardware', 'comp.graphics', 'comp.os.ms-windows.misc', 'alt.atheism', 'talk.politics.misc', 'sci.electronics', 'talk.politics.mideast', 'comp.windows.x', 'rec.sport.hockey', 'rec.sport.baseball', 'talk.religion.misc', 'sci.med', 'sci.crypt', 'rec.autos']\n",
            "Number of files in comp.graphics: 1000\n",
            "Some example filenames: ['39056', '38827', '38712', '37956', '38993']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgrMxmVHdbR9"
      },
      "source": [
        "Here's a example of what one file contains:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8BJEzsGdbR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2b2bcb-141f-4056-f810-67f389e57fe9"
      },
      "source": [
        "print(open(data_dir / \"comp.graphics\" / \"38987\").read())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Newsgroups: comp.graphics\n",
            "Path: cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!agate!dog.ee.lbl.gov!network.ucsd.edu!usc!rpi!nason110.its.rpi.edu!mabusj\n",
            "From: mabusj@nason110.its.rpi.edu (Jasen M. Mabus)\n",
            "Subject: Looking for Brain in CAD\n",
            "Message-ID: <c285m+p@rpi.edu>\n",
            "Nntp-Posting-Host: nason110.its.rpi.edu\n",
            "Reply-To: mabusj@rpi.edu\n",
            "Organization: Rensselaer Polytechnic Institute, Troy, NY.\n",
            "Date: Thu, 29 Apr 1993 23:27:20 GMT\n",
            "Lines: 7\n",
            "\n",
            "Jasen Mabus\n",
            "RPI student\n",
            "\n",
            "\tI am looking for a hman brain in any CAD (.dxf,.cad,.iges,.cgm,etc.) or picture (.gif,.jpg,.ras,etc.) format for an animation demonstration. If any has or knows of a location please reply by e-mail to mabusj@rpi.edu.\n",
            "\n",
            "Thank you in advance,\n",
            "Jasen Mabus  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1P6pQFLdbR9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-VwkLJYdbR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d28a2fde-04f4-4593-c124-719d6e2ca09a"
      },
      "source": [
        "samples = []\n",
        "labels = []\n",
        "class_names = []\n",
        "class_index = 0\n",
        "for dirname in sorted(os.listdir(data_dir)):\n",
        "    class_names.append(dirname)\n",
        "    dirpath = data_dir / dirname\n",
        "    fnames = os.listdir(dirpath)\n",
        "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
        "    for fname in fnames:\n",
        "        fpath = dirpath / fname\n",
        "        f = open(fpath, encoding=\"latin-1\")\n",
        "        content = f.read()\n",
        "        lines = content.split(\"\\n\")\n",
        "        lines = lines[10:]\n",
        "        content = \"\\n\".join(lines)\n",
        "        samples.append(content)\n",
        "        labels.append(class_index)\n",
        "    class_index += 1\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Number of samples:\", len(samples))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing alt.atheism, 1000 files found\n",
            "Processing comp.graphics, 1000 files found\n",
            "Processing comp.os.ms-windows.misc, 1000 files found\n",
            "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
            "Processing comp.sys.mac.hardware, 1000 files found\n",
            "Processing comp.windows.x, 1000 files found\n",
            "Processing misc.forsale, 1000 files found\n",
            "Processing rec.autos, 1000 files found\n",
            "Processing rec.motorcycles, 1000 files found\n",
            "Processing rec.sport.baseball, 1000 files found\n",
            "Processing rec.sport.hockey, 1000 files found\n",
            "Processing sci.crypt, 1000 files found\n",
            "Processing sci.electronics, 1000 files found\n",
            "Processing sci.med, 1000 files found\n",
            "Processing sci.space, 1000 files found\n",
            "Processing soc.religion.christian, 997 files found\n",
            "Processing talk.politics.guns, 1000 files found\n",
            "Processing talk.politics.mideast, 1000 files found\n",
            "Processing talk.politics.misc, 1000 files found\n",
            "Processing talk.religion.misc, 1000 files found\n",
            "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
            "Number of samples: 19997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rgh0VNXdbR9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj6SwZr5dbR9"
      },
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-rFrN9ndbR9"
      },
      "source": [
        "## vocabulary index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTaSkqs2dbR9"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJwn3egRdbR9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBOj1jzddbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e32ecc2-60d2-42c0-854a-fc2233f01e2c"
      },
      "source": [
        "vectorizer.get_vocabulary()[:5]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'to', 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjyBGSYhdbR-"
      },
      "source": [
        "Let's vectorize a test sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf20ZO4UdbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a12e56-90ed-4d5d-9c6e-4ccd0067a9fd"
      },
      "source": [
        "output = vectorizer([[\"the cat sat on the mat\"]])\n",
        "output.numpy()[0, :6]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2, 3468, 1690,   15,    2, 6295])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ2ln9G4dbR-"
      },
      "source": [
        "As you can see, \"the\" gets represented as \"2\". Why not 0, given that \"the\" was the first\n",
        "word in the vocabulary? That's because index 0 is reserved for padding and index 1 is\n",
        "reserved for \"out of vocabulary\" tokens.\n",
        "\n",
        "Here's a dict mapping words to their indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY-HMwd2dbR-"
      },
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch7wmh_pdbR-"
      },
      "source": [
        "As you can see, we obtain the same encoding as above for our test sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oATyrrt_dbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e633c09-c616-46c6-9cc4-f26adc707ba5"
      },
      "source": [
        "test = [\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "[word_index[w] for w in test]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3468, 1690, 15, 2, 6295]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf7XxTLWdbR-"
      },
      "source": [
        "## Load pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AZYjONqemeL",
        "outputId": "5e2c0150-c82f-4af4-a3ae-a776000dd41a"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-26 02:55:47--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-11-26 02:55:47--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-11-26 02:55:47--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.04MB/s    in 6m 36s  \n",
            "\n",
            "2020-11-26 03:02:23 (2.08 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wEln6hWhP1F",
        "outputId": "7cd7fe91-3a50-4e33-d15a-d17eee81829e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M-kmIT6dbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293aeb36-50e3-44d0-94d4-f49f0ee9a047"
      },
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL2ifo6UdbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31317fb6-a043-4a85-8022-a0038d7ad705"
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converted 17972 words (2028 misses)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chip65radbR-"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6VZcDUgdbR-"
      },
      "source": [
        "## Build the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c78QHgWOdbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "272f27fe-5e82-4bd6-9c93-43904fffbf9b"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded_sequences = embedding_layer(int_sequences_input)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling1D(5)(x)\n",
        "x = layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "preds = layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
        "model = keras.Model(int_sequences_input, preds)\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, None, 100)         2000200   \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, None, 128)         64128     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 20)                2580      \n",
            "=================================================================\n",
            "Total params: 2,247,516\n",
            "Trainable params: 247,316\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akx3DN6qdbR-"
      },
      "source": [
        "## Train the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk_uW-gddbR-"
      },
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9vPsCMEdbR-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmlXrf7SdbR-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0524bf06-d20a-4849-e2bc-b77024181c6d"
      },
      "source": [
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "125/125 [==============================] - 30s 238ms/step - loss: 2.9959 - acc: 0.0469 - val_loss: 2.9959 - val_acc: 0.0490\n",
            "Epoch 2/20\n",
            "125/125 [==============================] - 31s 246ms/step - loss: 2.9959 - acc: 0.0474 - val_loss: 2.9960 - val_acc: 0.0470\n",
            "Epoch 3/20\n",
            "125/125 [==============================] - 30s 238ms/step - loss: 2.9959 - acc: 0.0464 - val_loss: 2.9961 - val_acc: 0.0470\n",
            "Epoch 4/20\n",
            "125/125 [==============================] - 29s 235ms/step - loss: 2.9958 - acc: 0.0495 - val_loss: 2.9961 - val_acc: 0.0470\n",
            "Epoch 5/20\n",
            "125/125 [==============================] - 29s 234ms/step - loss: 2.9959 - acc: 0.0495 - val_loss: 2.9961 - val_acc: 0.0470\n",
            "Epoch 6/20\n",
            "125/125 [==============================] - 29s 234ms/step - loss: 2.9959 - acc: 0.0483 - val_loss: 2.9961 - val_acc: 0.0470\n",
            "Epoch 7/20\n",
            "125/125 [==============================] - 29s 236ms/step - loss: 2.9959 - acc: 0.0488 - val_loss: 2.9962 - val_acc: 0.0470\n",
            "Epoch 8/20\n",
            "125/125 [==============================] - 29s 235ms/step - loss: 2.9958 - acc: 0.0485 - val_loss: 2.9962 - val_acc: 0.0470\n",
            "Epoch 9/20\n",
            "125/125 [==============================] - 29s 234ms/step - loss: 2.9958 - acc: 0.0476 - val_loss: 2.9962 - val_acc: 0.0470\n",
            "Epoch 10/20\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 2.9958 - acc: 0.0469 - val_loss: 2.9962 - val_acc: 0.0470\n",
            "Epoch 11/20\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 2.9959 - acc: 0.0489 - val_loss: 2.9962 - val_acc: 0.0475\n",
            "Epoch 12/20\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 2.9958 - acc: 0.0493 - val_loss: 2.9962 - val_acc: 0.0470\n",
            "Epoch 13/20\n",
            "125/125 [==============================] - 29s 235ms/step - loss: 2.9958 - acc: 0.0474 - val_loss: 2.9962 - val_acc: 0.0480\n",
            "Epoch 14/20\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 2.9959 - acc: 0.0464 - val_loss: 2.9962 - val_acc: 0.0475\n",
            "Epoch 15/20\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 2.9959 - acc: 0.0472 - val_loss: 2.9963 - val_acc: 0.0470\n",
            "Epoch 16/20\n",
            "125/125 [==============================] - 29s 232ms/step - loss: 2.9958 - acc: 0.0484 - val_loss: 2.9963 - val_acc: 0.0470\n",
            "Epoch 17/20\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 2.9959 - acc: 0.0493 - val_loss: 2.9963 - val_acc: 0.0470\n",
            "Epoch 18/20\n",
            "125/125 [==============================] - 29s 233ms/step - loss: 2.9959 - acc: 0.0488 - val_loss: 2.9963 - val_acc: 0.0475\n",
            "Epoch 19/20\n",
            "125/125 [==============================] - 29s 234ms/step - loss: 2.9959 - acc: 0.0488 - val_loss: 2.9963 - val_acc: 0.0470\n",
            "Epoch 20/20\n",
            "125/125 [==============================] - 29s 235ms/step - loss: 2.9958 - acc: 0.0489 - val_loss: 2.9963 - val_acc: 0.0475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa93e61e828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZgxsAEodbR-"
      },
      "source": [
        "## Export  model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nvgZgcXdbR-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "634f1712-2dcb-4aec-8e46-60696657855b"
      },
      "source": [
        "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = vectorizer(string_input)\n",
        "preds = model(x)\n",
        "end_to_end_model = keras.Model(string_input, preds)\n",
        "\n",
        "probabilities = end_to_end_model.predict(\n",
        "    [[\"this message is about computer graphics and 3D modeling\"]]\n",
        ")\n",
        "\n",
        "class_names[np.argmax(probabilities[0])]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sci.med'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}