{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment 6:_TFX_interactivecontext_based_mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_Sec49AdvanceDL/blob/master/Assignment_6/Assignment_6__TFX_interactivecontext_based_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdeKOEkv1Fe8"
      },
      "source": [
        "# CMPE297-49 Assignment 6: TFX interactivecontext based colab\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GivNBNYjb3b"
      },
      "source": [
        "## Installing and Importing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmgi8ZvQkScg"
      },
      "source": [
        "### Upgrade Pip\n",
        "\n",
        "To avoid upgrading Pip in a system when running locally, check to make sure that we're running in Colab.  Local systems can of course be upgraded separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as4OTe2ukSqm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa865ddb-9c4b-4471-8760-7c0a1498f136"
      },
      "source": [
        "try:\n",
        "  import colab\n",
        "  !pip install --upgrade pip\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/11/2dc62c5263d9eb322f2f028f7b56cd9d096bb8988fcf82d65fa2e4057afe/pip-20.3.1-py2.py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 27.0MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 31.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 36.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 29.2MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 29.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 31.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 27.6MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 25.1MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 26.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 24.8MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 24.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 24.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 24.8MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 24.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 24.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 24.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 24.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 184kB 24.8MB/s eta 0:00:01\r\u001b[K     |████                            | 194kB 24.8MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 24.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 24.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 358kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 368kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 389kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 399kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 532kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 542kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 552kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 563kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 573kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 583kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 593kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 604kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 716kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 727kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 737kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 747kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 768kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 778kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 788kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 798kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 890kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 911kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 921kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 931kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 942kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 952kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 962kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 972kB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 983kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.0MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.3MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 24.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 24.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-20.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZOYTt1RW4TK"
      },
      "source": [
        "### \n",
        "**Note: In Google Colab,you must restart the runtime at first time upgrade**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4SQA7Q5nej3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0a2596-13f9-498d-899a-780a2805fc8c"
      },
      "source": [
        "!pip install -q -U --use-feature=2020-resolver tfx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 12.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 43.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 151 kB 71.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 69.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 63.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 79.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 173 kB 68.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 114 kB 71.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 267 kB 82.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 91 kB 13.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 91 kB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 91 kB 13.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 91 kB 13.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 91 kB 12.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 91 kB 13.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 169 kB 78.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 85.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 255 kB 86.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 183 kB 79.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 435 kB 80.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 862 kB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 66.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 504 kB 83.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 71.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63.8 MB 24 kB/s \n",
            "\u001b[K     |████████████████████████████████| 269 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 76.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 63.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 103 kB 72.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 64.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 785 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 355 kB 77.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 378 kB 65.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 200 kB 83.7 MB/s \n",
            "\u001b[?25h  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for grpc-google-iam-v1 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for proto-plus (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.11.1 requires dill>=0.3.3, but you have dill 0.3.1.1 which is incompatible.\n",
            "jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.8 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth~=1.17.2, but you have google-auth 1.24.0 which is incompatible.\n",
            "google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.16.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIqpWK9efviJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4d10c3-4e29-42ec-cb0f-c011b94294da"
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "import urllib\n",
        "\n",
        "import absl\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_analysis as tfma\n",
        "tf.get_logger().propagate = False\n",
        "pp = pprint.PrettyPrinter()\n",
        "\n",
        "import tfx\n",
        "from tfx.components import CsvExampleGen, Evaluator, ExampleValidator, Pusher\n",
        "from tfx.components import ResolverNode, SchemaGen, StatisticsGen, Trainer, Transform\n",
        "from tfx.components.base import executor_spec\n",
        "from tfx.components.trainer.executor import GenericExecutor\n",
        "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
        "from tfx.orchestration import metadata, pipeline\n",
        "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
        "from tfx.proto import pusher_pb2, trainer_pb2\n",
        "from tfx.types import Channel\n",
        "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
        "from tfx.utils.dsl_utils import external_input\n",
        "\n",
        "\n",
        "%load_ext tfx.orchestration.experimental.interactive.notebook_extensions.skip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:RuntimeParameter is only supported on Cloud-based DAG runner currently.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ4K18_DN2D8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5a968b-96fb-4364-ea7d-64a38db908de"
      },
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))\n",
        "print('TFX version: {}'.format(tfx.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n",
            "TFX version: 0.25.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufJKQ6OvkJlY"
      },
      "source": [
        "### Set up pipeline paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad5JLpKbf6sN"
      },
      "source": [
        "_tfx_root = tfx.__path__[0]\n",
        "\n",
        "#mnist data root\n",
        "_mnist_root =  os.path.join(_tfx_root, 'examples/mnist')\n",
        "\n",
        "#cifar10\n",
        "_cifar10 =  os.path.join(_tfx_root, 'examples/cifar10')\n",
        "\n",
        "#imdb\n",
        "_imdb = os.path.join(_tfx_root, 'examples/imdb')\n",
        "\n",
        "#iris\n",
        "_iris = os.path.join(_tfx_root, 'examples/iris')\n",
        "\n",
        "#mnist_pipeline\n",
        "_mnist_root = os.path.join(_tfx_root, 'examples/mnist_pipeline')\n",
        "\n",
        "#probablity_of_customer_compliants\n",
        "_probablity =  os.path.join(_tfx_root, 'examples/probablity_of_customer_compliants')\n",
        "\n",
        "_serving_model_dir_mnist = os.path.join(tempfile.mkdtemp(), 'serving_model/mnist_simple')\n",
        "_serving_model_dir_cifar10 = os.path.join(tempfile.mkdtemp(), 'serving_model/cifar10_simple')\n",
        "_serving_model_dir_imdb = os.path.join(tempfile.mkdtemp(), 'serving_model/imdb_simple')\n",
        "_serving_model_dir_iris = os.path.join(tempfile.mkdtemp(), 'serving_model/iris_simple')\n",
        "_serving_model_dir_mnist = os.path.join(tempfile.mkdtemp(), 'serving_model/mnist_simple')\n",
        "_serving_model_dir_probablity = os.path.join(tempfile.mkdtemp(), 'serving_model/probablity')\n",
        "\n",
        "absl.logging.set_verbosity(absl.logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2cMMAbSkGfX"
      },
      "source": [
        "### Download example data\n",
        "Download the example dataset for use in our TFX pipeline.\n",
        "* mnist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ipWUBDd6vA"
      },
      "source": [
        "This example does not use the Estimator API for model training/evaluation.\r\n",
        "\r\n",
        "The trainer must be configured with TFX [Generic Trainer] (https://github.com/tensorflow/community/blob/master/rfcs/20200117-tfx-generic-trainer.md).\r\n",
        "\r\n",
        "The dataset included in this example consists of a selection of 1000 records from the MNIST dataset, converted to tfrecord format. Each record is a tf.Example with 2 columns of data: 'image_floats' representing the 28x28 image as 784 float values in the range [-0.5, 0.5], and 'image_class' representing the label with values [0-9] corresponding to decimal digit in the image.\r\n",
        "\r\n",
        "For a detailed description of tf.Example and TFRecord see https://www.tensorflow.org/tutorials/load_data/tfrecord. Several independently written tools can be used to generate the tfrecords from images. See Preparing MNIST data from one such publicly available set of instructions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSrdK7ZgeA9f",
        "outputId": "877ad1b0-8032-4cb5-ac1b-0dfaef91e809"
      },
      "source": [
        "!virtualenv -p python3.5 mnist\r\n",
        "!source ./mnist/bin/activate"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: virtualenv: command not found\n",
            "/bin/bash: ./mnist/bin/activate: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7g0nuSveJ6H",
        "outputId": "e1ad7dd2-3d67-4330-b061-02342fd93345"
      },
      "source": [
        "!git clone https://github.com/tensorflow/tfx ~/tfx-source && pushd ~/tfx-source\r\n",
        "!cp -r ~/tfx-source/tfx/examples/mnist ~/"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/root/tfx-source'...\n",
            "remote: Enumerating objects: 111, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 31845 (delta 50), reused 58 (delta 30), pack-reused 31734\u001b[K\n",
            "Receiving objects: 100% (31845/31845), 181.62 MiB | 34.25 MiB/s, done.\n",
            "Resolving deltas: 100% (23924/23924), done.\n",
            "~/tfx-source /tmp/tfx-data-mnistf3ddmh9v\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGFRW3bpeR0t"
      },
      "source": [
        "from __future__ import absolute_import\r\n",
        "from __future__ import division\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "import os\r\n",
        "from typing import List, Text\r\n",
        "\r\n",
        "import absl\r\n",
        "import tensorflow_model_analysis as tfma\r\n",
        "from tfx.components import Evaluator\r\n",
        "from tfx.components import ExampleValidator\r\n",
        "from tfx.components import ImportExampleGen\r\n",
        "from tfx.components import Pusher\r\n",
        "from tfx.components import SchemaGen\r\n",
        "from tfx.components import StatisticsGen\r\n",
        "from tfx.components import Trainer\r\n",
        "from tfx.components import Transform\r\n",
        "from tfx.components.trainer.executor import GenericExecutor\r\n",
        "from tfx.dsl.components.base import executor_spec\r\n",
        "from tfx.orchestration import metadata\r\n",
        "from tfx.orchestration import pipeline\r\n",
        "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\r\n",
        "from tfx.proto import pusher_pb2\r\n",
        "from tfx.proto import trainer_pb2\r\n",
        "from tfx.utils.dsl_utils import external_input\r\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bpscwppfJS8"
      },
      "source": [
        "_pipeline_name = 'mnist_native_keras'\r\n",
        "\r\n",
        "_mnist_root = os.path.join(os.environ['HOME'], 'mnist')\r\n",
        "_data_root = os.path.join(_mnist_root, 'data')\r\n",
        "\r\n",
        "_module_file = os.path.join(_mnist_root, 'mnist_utils_native_keras.py')\r\n",
        "_module_file_lite = os.path.join(\r\n",
        "    _mnist_root, 'mnist_utils_native_keras_lite.py')\r\n",
        "\r\n",
        "\r\n",
        "_serving_model_dir = os.path.join(_mnist_root, 'serving_model', _pipeline_name)\r\n",
        "_serving_model_dir_lite = os.path.join(\r\n",
        "    _mnist_root, 'serving_model_lite', _pipeline_name)\r\n",
        "\r\n",
        "_tfx_root = os.path.join(os.environ['HOME'], 'tfx')\r\n",
        "_pipeline_root = os.path.join(_tfx_root, 'pipelines', _pipeline_name)\r\n",
        "\r\n",
        "_metadata_path = os.path.join(_tfx_root, 'metadata', _pipeline_name,\r\n",
        "                              'metadata.db')\r\n",
        "\r\n",
        "\r\n",
        "_beam_pipeline_args = [\r\n",
        "    '--direct_running_mode=multi_processing',\r\n",
        "    # 0 means auto-detect based on on the number of CPUs available\r\n",
        "    # during execution time.\r\n",
        "    '--direct_num_workers=0',\r\n",
        "]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jIM1lBye0wZ"
      },
      "source": [
        "def _create_pipeline(pipeline_name: Text, pipeline_root: Text, data_root: Text,\r\n",
        "                     module_file: Text, module_file_lite: Text,\r\n",
        "                     serving_model_dir: Text, serving_model_dir_lite: Text,\r\n",
        "                     metadata_path: Text,\r\n",
        "                     beam_pipeline_args: List[Text]) -> pipeline.Pipeline:\r\n",
        "  \"\"\"Implements the handwritten digit classification example using TFX.\"\"\"\r\n",
        "  examples = external_input(data_root)\r\n",
        "\r\n",
        "  # Brings data into the pipeline.\r\n",
        "  example_gen = ImportExampleGen(input=examples)\r\n",
        "\r\n",
        "  # Computes statistics over data for visualization and example validation.\r\n",
        "  statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\r\n",
        "\r\n",
        "  # Generates schema based on statistics files.\r\n",
        "  schema_gen = SchemaGen(\r\n",
        "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\r\n",
        "\r\n",
        "  # Performs anomaly detection based on statistics and data schema.\r\n",
        "  example_validator = ExampleValidator(\r\n",
        "      statistics=statistics_gen.outputs['statistics'],\r\n",
        "      schema=schema_gen.outputs['schema'])\r\n",
        "\r\n",
        "  # Performs transformations and feature engineering in training and serving.\r\n",
        "  transform = Transform(\r\n",
        "      examples=example_gen.outputs['examples'],\r\n",
        "      schema=schema_gen.outputs['schema'],\r\n",
        "      module_file=module_file)\r\n",
        "\r\n",
        "  def _create_trainer(module_file, instance_name):\r\n",
        "    return Trainer(\r\n",
        "        module_file=module_file,\r\n",
        "        custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\r\n",
        "        examples=transform.outputs['transformed_examples'],\r\n",
        "        transform_graph=transform.outputs['transform_graph'],\r\n",
        "        schema=schema_gen.outputs['schema'],\r\n",
        "        train_args=trainer_pb2.TrainArgs(num_steps=5000),\r\n",
        "        eval_args=trainer_pb2.EvalArgs(num_steps=100),\r\n",
        "        instance_name=instance_name)\r\n",
        "\r\n",
        "  # Uses user-provided Python function that trains a Keras model.\r\n",
        "  trainer = _create_trainer(module_file, 'mnist')\r\n",
        "\r\n",
        "  # Trains the same model as the one above, but converts it into a TFLite one.\r\n",
        "  trainer_lite = _create_trainer(module_file_lite, 'mnist_lite')\r\n",
        "\r\n",
        "  # TODO(b/150949276): Add resolver back once it supports two trainers.\r\n",
        "\r\n",
        "  # Uses TFMA to compute an evaluation statistics over features of a model and\r\n",
        "  # performs quality validation of a candidate model.\r\n",
        "  eval_config = tfma.EvalConfig(\r\n",
        "      model_specs=[tfma.ModelSpec(label_key='image_class')],\r\n",
        "      slicing_specs=[tfma.SlicingSpec()],\r\n",
        "      metrics_specs=[\r\n",
        "          tfma.MetricsSpec(metrics=[\r\n",
        "              tfma.MetricConfig(\r\n",
        "                  class_name='SparseCategoricalAccuracy',\r\n",
        "                  threshold=tfma.config.MetricThreshold(\r\n",
        "                      value_threshold=tfma.GenericValueThreshold(\r\n",
        "                          lower_bound={'value': 0.8})))\r\n",
        "          ])\r\n",
        "      ])\r\n",
        "\r\n",
        "  eval_config_lite = tfma.EvalConfig()\r\n",
        "  eval_config_lite.CopyFrom(eval_config)\r\n",
        "  # Informs the evaluator that the model is a TFLite model.\r\n",
        "  eval_config_lite.model_specs[0].model_type = 'tf_lite'\r\n",
        "\r\n",
        "  # Uses TFMA to compute the evaluation statistics over features of a model.\r\n",
        "  evaluator = Evaluator(\r\n",
        "      examples=example_gen.outputs['examples'],\r\n",
        "      model=trainer.outputs['model'],\r\n",
        "      eval_config=eval_config,\r\n",
        "      instance_name='mnist')\r\n",
        "\r\n",
        "  # Uses TFMA to compute the evaluation statistics over features of a TFLite\r\n",
        "  # model.\r\n",
        "  evaluator_lite = Evaluator(\r\n",
        "      examples=example_gen.outputs['examples'],\r\n",
        "      model=trainer_lite.outputs['model'],\r\n",
        "      eval_config=eval_config_lite,\r\n",
        "      instance_name='mnist_lite')\r\n",
        "\r\n",
        "  # Checks whether the model passed the validation steps and pushes the model\r\n",
        "  # to a file destination if check passed.\r\n",
        "  pusher = Pusher(\r\n",
        "      model=trainer.outputs['model'],\r\n",
        "      model_blessing=evaluator.outputs['blessing'],\r\n",
        "      push_destination=pusher_pb2.PushDestination(\r\n",
        "          filesystem=pusher_pb2.PushDestination.Filesystem(\r\n",
        "              base_directory=serving_model_dir)),\r\n",
        "      instance_name='mnist')\r\n",
        "\r\n",
        "  # Checks whether the TFLite model passed the validation steps and pushes the\r\n",
        "  # model to a file destination if check passed.\r\n",
        "  pusher_lite = Pusher(\r\n",
        "      model=trainer_lite.outputs['model'],\r\n",
        "      model_blessing=evaluator_lite.outputs['blessing'],\r\n",
        "      push_destination=pusher_pb2.PushDestination(\r\n",
        "          filesystem=pusher_pb2.PushDestination.Filesystem(\r\n",
        "              base_directory=serving_model_dir_lite)),\r\n",
        "      instance_name='mnist_lite')\r\n",
        "\r\n",
        "  return pipeline.Pipeline(\r\n",
        "      pipeline_name=pipeline_name,\r\n",
        "      pipeline_root=pipeline_root,\r\n",
        "      components=[\r\n",
        "          example_gen,\r\n",
        "          statistics_gen,\r\n",
        "          schema_gen,\r\n",
        "          example_validator,\r\n",
        "          transform,\r\n",
        "          trainer,\r\n",
        "          trainer_lite,\r\n",
        "          evaluator,\r\n",
        "          evaluator_lite,\r\n",
        "          pusher,\r\n",
        "          pusher_lite,\r\n",
        "      ],\r\n",
        "      enable_cache=True,\r\n",
        "      metadata_connection_config=metadata.sqlite_metadata_connection_config(\r\n",
        "          metadata_path),\r\n",
        "      beam_pipeline_args=beam_pipeline_args)\r\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gry0OhggmHC",
        "outputId": "ae5b1e17-a363-4c71-b921-70152e79ab4d"
      },
      "source": [
        "absl.logging.set_verbosity(absl.logging.INFO)\r\n",
        "pipeline_1=_create_pipeline(pipeline_name=_pipeline_name, pipeline_root=_pipeline_root,\r\n",
        "          data_root=_data_root, module_file=_module_file,\r\n",
        "          module_file_lite=_module_file_lite, serving_model_dir=_serving_model_dir,\r\n",
        "          serving_model_dir_lite=_serving_model_dir_lite,\r\n",
        "          metadata_path=_metadata_path, beam_pipeline_args=_beam_pipeline_args)\r\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:The \"input\" argument to the ImportExampleGen component has been deprecated by \"input_base\". Please update your usage as support for this argument will be removed soon.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "INFO:absl:Excluding no splits because exclude_splits is not set.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n",
            "WARNING:absl:`instance_name` is deprecated, please set node id directly using`with_id()` or `.id` setter.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGOUEqfsg4Jy",
        "outputId": "ae434465-428f-4b08-f804-1a33dbf32ae1"
      },
      "source": [
        "BeamDagRunner().run(pipeline_1)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Component ImportExampleGen depends on [].\n",
            "INFO:absl:Component ImportExampleGen is scheduled.\n",
            "INFO:absl:Component StatisticsGen depends on ['Run[ImportExampleGen]'].\n",
            "INFO:absl:Component StatisticsGen is scheduled.\n",
            "INFO:absl:Component SchemaGen depends on ['Run[StatisticsGen]'].\n",
            "INFO:absl:Component SchemaGen is scheduled.\n",
            "INFO:absl:Component ExampleValidator depends on ['Run[StatisticsGen]', 'Run[SchemaGen]'].\n",
            "INFO:absl:Component ExampleValidator is scheduled.\n",
            "INFO:absl:Component Transform depends on ['Run[SchemaGen]', 'Run[ImportExampleGen]'].\n",
            "INFO:absl:Component Transform is scheduled.\n",
            "INFO:absl:Component Trainer.mnist depends on ['Run[SchemaGen]', 'Run[Transform]'].\n",
            "INFO:absl:Component Trainer.mnist is scheduled.\n",
            "INFO:absl:Component Trainer.mnist_lite depends on ['Run[SchemaGen]', 'Run[Transform]'].\n",
            "INFO:absl:Component Trainer.mnist_lite is scheduled.\n",
            "INFO:absl:Component Evaluator.mnist depends on ['Run[Trainer.mnist]', 'Run[ImportExampleGen]'].\n",
            "INFO:absl:Component Evaluator.mnist is scheduled.\n",
            "INFO:absl:Component Evaluator.mnist_lite depends on ['Run[ImportExampleGen]', 'Run[Trainer.mnist_lite]'].\n",
            "INFO:absl:Component Evaluator.mnist_lite is scheduled.\n",
            "INFO:absl:Component Pusher.mnist depends on ['Run[Trainer.mnist]', 'Run[Evaluator.mnist]'].\n",
            "INFO:absl:Component Pusher.mnist is scheduled.\n",
            "INFO:absl:Component Pusher.mnist_lite depends on ['Run[Trainer.mnist_lite]', 'Run[Evaluator.mnist_lite]'].\n",
            "INFO:absl:Component Pusher.mnist_lite is scheduled.\n",
            "INFO:absl:Component ImportExampleGen is running.\n",
            "INFO:absl:Running driver for ImportExampleGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:select span and version = (0, None)\n",
            "INFO:absl:latest span and version = (0, None)\n",
            "INFO:absl:Running publisher for ImportExampleGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component ImportExampleGen is finished.\n",
            "INFO:absl:Component StatisticsGen is running.\n",
            "INFO:absl:Running driver for StatisticsGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running publisher for StatisticsGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component StatisticsGen is finished.\n",
            "INFO:absl:Component SchemaGen is running.\n",
            "INFO:absl:Running driver for SchemaGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running publisher for SchemaGen\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component SchemaGen is finished.\n",
            "INFO:absl:Component Transform is running.\n",
            "INFO:absl:Running driver for Transform\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Transform\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpty6nubb6/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpty6nubb6/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpty6nubb6/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpty6nubb6/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Analyze the 'train' split and transform all splits when splits_config is not set.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TFT beam APIs accept both the TFXIO format and the instance dict format now. There is no need to set use_tfxio any more and it will be removed soon.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n",
            "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[str, Union[NoneType, _Dataset]], Union[Dict[str, Dict[str, PCollection]], NoneType]] instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Counter' object has no attribute 'name'\n",
            "INFO:tensorflow:SavedModel written to: /root/tfx/pipelines/mnist_native_keras/Transform/transform_graph/10/.temp_path/tftransform_tmp/520e963fc40246aa86aecb640f0c9ef7/saved_model.pb\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
            "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
            "'Counter' object has no attribute 'name'\n",
            "INFO:tensorflow:SavedModel written to: /root/tfx/pipelines/mnist_native_keras/Transform/transform_graph/10/.temp_path/tftransform_tmp/df774ff79bc142cdb317b4dd84c10dde/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "INFO:absl:Feature image_class has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
            "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
            "INFO:absl:Running publisher for Transform\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Transform is finished.\n",
            "INFO:absl:Component Trainer.mnist_lite is running.\n",
            "INFO:absl:Running driver for Trainer.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Trainer.mnist_lite\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpmfmhet8u/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpmfmhet8u/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpmfmhet8u/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpmfmhet8u/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
            "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Model: \"sequential\"\n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:Layer (type)                 Output Shape              Param #   \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:dense (Dense)                (None, 64)                50240     \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout (Dropout)            (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_1 (Dense)              (None, 64)                4160      \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout_1 (Dropout)          (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_2 (Dense)              (None, 10)                650       \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:Total params: 55,050\n",
            "INFO:absl:Trainable params: 55,050\n",
            "INFO:absl:Non-trainable params: 0\n",
            "INFO:absl:_________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "   1/5000 [..............................] - ETA: 2s - loss: 2.3220 - sparse_categorical_accuracy: 0.1750WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "   2/5000 [..............................] - ETA: 2:13 - loss: 2.4958 - sparse_categorical_accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0111s vs `on_train_batch_end` time: 0.0418s). Check your callbacks.\n",
            "4993/5000 [============================>.] - ETA: 0s - loss: 0.1401 - sparse_categorical_accuracy: 0.9519INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "5000/5000 [==============================] - 23s 5ms/step - loss: 0.1399 - sparse_categorical_accuracy: 0.9519 - val_loss: 1.3395 - val_sparse_categorical_accuracy: 0.8342\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/11/serving_model_dir/temp/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
            "INFO:absl:Training complete. Model written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/11/serving_model_dir. ModelRun written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model_run/11\n",
            "INFO:absl:Running publisher for Trainer.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Trainer.mnist_lite is finished.\n",
            "INFO:absl:Component Evaluator.mnist_lite is running.\n",
            "INFO:absl:Running driver for Evaluator.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Evaluator.mnist_lite\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpazil8n1s/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpazil8n1s/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpazil8n1s/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpazil8n1s/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "WARNING:absl:\"maybe_add_baseline\" and \"maybe_remove_baseline\" are deprecated,\n",
            "        please use \"has_baseline\" instead.\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"image_class\"\n",
            "  model_type: \"tf_lite\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"SparseCategoricalAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using /root/tfx/pipelines/mnist_native_keras/Trainer.mnist_lite/model/11/serving_model_dir as  model.\n",
            "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
            "INFO:absl:Evaluating model.\n",
            "INFO:absl:Evaluation complete. Results written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist_lite/evaluation/12.\n",
            "INFO:absl:Checking validation results.\n",
            "INFO:absl:Blessing result True written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist_lite/blessing/12.\n",
            "INFO:absl:Running publisher for Evaluator.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Evaluator.mnist_lite is finished.\n",
            "INFO:absl:Component Pusher.mnist_lite is running.\n",
            "INFO:absl:Running driver for Pusher.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Pusher.mnist_lite\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpspmyo386/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpspmyo386/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpspmyo386/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpspmyo386/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Model version: 1607836400\n",
            "INFO:absl:Model written to serving path /root/mnist/serving_model_lite/mnist_native_keras/1607836400.\n",
            "INFO:absl:Model pushed to /root/tfx/pipelines/mnist_native_keras/Pusher.mnist_lite/pushed_model/13.\n",
            "INFO:absl:Running publisher for Pusher.mnist_lite\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Pusher.mnist_lite is finished.\n",
            "INFO:absl:Component ExampleValidator is running.\n",
            "INFO:absl:Running driver for ExampleValidator\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for ExampleValidator\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpprcinxiz/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpprcinxiz/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpprcinxiz/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpprcinxiz/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Validating schema against the computed statistics for split train.\n",
            "INFO:absl:Validation complete for split train. Anomalies written to /root/tfx/pipelines/mnist_native_keras/ExampleValidator/anomalies/14/train.\n",
            "INFO:absl:Validating schema against the computed statistics for split eval.\n",
            "INFO:absl:Validation complete for split eval. Anomalies written to /root/tfx/pipelines/mnist_native_keras/ExampleValidator/anomalies/14/eval.\n",
            "INFO:absl:Running publisher for ExampleValidator\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component ExampleValidator is finished.\n",
            "INFO:absl:Component Trainer.mnist is running.\n",
            "INFO:absl:Running driver for Trainer.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Trainer.mnist\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpznt5by84/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpznt5by84/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpznt5by84/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpznt5by84/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
            "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
            "INFO:absl:Training model.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_class_xf has a shape dim {\n",
            "  size: 1\n",
            "}\n",
            ". Setting to DenseTensor.\n",
            "INFO:absl:Feature image_floats_xf has a shape dim {\n",
            "  size: 784\n",
            "}\n",
            ". Setting to DenseTensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Model: \"sequential_1\"\n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:Layer (type)                 Output Shape              Param #   \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:dense_3 (Dense)              (None, 64)                50240     \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout_2 (Dropout)          (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_4 (Dense)              (None, 64)                4160      \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dropout_3 (Dropout)          (None, 64)                0         \n",
            "INFO:absl:_________________________________________________________________\n",
            "INFO:absl:dense_5 (Dense)              (None, 10)                650       \n",
            "INFO:absl:=================================================================\n",
            "INFO:absl:Total params: 55,050\n",
            "INFO:absl:Trainable params: 55,050\n",
            "INFO:absl:Non-trainable params: 0\n",
            "INFO:absl:_________________________________________________________________\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   2/5000 [..............................] - ETA: 2:42 - loss: 2.3957 - sparse_categorical_accuracy: 0.1000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0548s). Check your callbacks.\n",
            "5000/5000 [==============================] - 24s 5ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9669 - val_loss: 1.6363 - val_sparse_categorical_accuracy: 0.8188\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Assets written to: /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/15/serving_model_dir/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Training complete. Model written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/15/serving_model_dir. ModelRun written to /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model_run/15\n",
            "INFO:absl:Running publisher for Trainer.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Trainer.mnist is finished.\n",
            "INFO:absl:Component Evaluator.mnist is running.\n",
            "INFO:absl:Running driver for Evaluator.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Evaluator.mnist\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmp97d8cawi/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmp97d8cawi/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmp97d8cawi/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmp97d8cawi/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "WARNING:absl:\"maybe_add_baseline\" and \"maybe_remove_baseline\" are deprecated,\n",
            "        please use \"has_baseline\" instead.\n",
            "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
            "model_specs {\n",
            "  label_key: \"image_class\"\n",
            "}\n",
            "slicing_specs {\n",
            "}\n",
            "metrics_specs {\n",
            "  metrics {\n",
            "    class_name: \"SparseCategoricalAccuracy\"\n",
            "    threshold {\n",
            "      value_threshold {\n",
            "        lower_bound {\n",
            "          value: 0.8\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "INFO:absl:Using /root/tfx/pipelines/mnist_native_keras/Trainer.mnist/model/15/serving_model_dir as  model.\n",
            "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
            "INFO:absl:Evaluating model.\n",
            "INFO:absl:Evaluation complete. Results written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist/evaluation/16.\n",
            "INFO:absl:Checking validation results.\n",
            "INFO:absl:Blessing result True written to /root/tfx/pipelines/mnist_native_keras/Evaluator.mnist/blessing/16.\n",
            "INFO:absl:Running publisher for Evaluator.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Evaluator.mnist is finished.\n",
            "INFO:absl:Component Pusher.mnist is running.\n",
            "INFO:absl:Running driver for Pusher.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Running executor for Pusher.mnist\n",
            "INFO:absl:Attempting to infer TFX Python dependency for beam\n",
            "INFO:absl:Copying all content from install dir /usr/local/lib/python3.6/dist-packages/tfx to temp dir /tmp/tmpbtfwe47w/build/tfx\n",
            "INFO:absl:Generating a temp setup file at /tmp/tmpbtfwe47w/build/tfx/setup.py\n",
            "INFO:absl:Creating temporary sdist package, logs available at /tmp/tmpbtfwe47w/build/tfx/setup.log\n",
            "INFO:absl:Added --extra_package=/tmp/tmpbtfwe47w/build/tfx/dist/tfx_ephemeral-0.25.0.tar.gz to beam args\n",
            "INFO:absl:Model version: 1607836446\n",
            "INFO:absl:Model written to serving path /root/mnist/serving_model/mnist_native_keras/1607836446.\n",
            "INFO:absl:Model pushed to /root/tfx/pipelines/mnist_native_keras/Pusher.mnist/pushed_model/17.\n",
            "INFO:absl:Running publisher for Pusher.mnist\n",
            "INFO:absl:MetadataStore with DB connection initialized\n",
            "INFO:absl:Component Pusher.mnist is finished.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzKTPNlEblsD",
        "outputId": "34b3e6f9-4176-4a0b-8428-61f77db58f0d"
      },
      "source": [
        "! git clone https://github.com/tensorflow/tfx.git /tmp/tfx/"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/tmp/tfx'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 31845 (delta 50), reused 58 (delta 30), pack-reused 31736\u001b[K\n",
            "Receiving objects: 100% (31845/31845), 181.63 MiB | 33.32 MiB/s, done.\n",
            "Resolving deltas: 100% (23925/23925), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Y8unuqJbZwR",
        "outputId": "06e98aa1-212c-4d03-cb15-533df2455b08"
      },
      "source": [
        "!ls /tmp/tfx/tfx"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "benchmarks  dependencies.py  experimental   proto    tools  version.py\n",
            "BUILD\t    dsl\t\t     extensions     scripts  types  workspace.bzl\n",
            "components  examples\t     orchestration  tfx.bzl  utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6LxnrKIcXeA"
      },
      "source": [
        "! cp /tmp/tfx/tfx/examples/mnist/data/mnist.tfrecord /tmp/tfx-data-mnistf3ddmh9v/mnist.tfrecord"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68HOF8-Cajsl",
        "outputId": "55e80dbd-3b1d-4e41-dd70-76bc5b546ee3"
      },
      "source": [
        "%cd /tmp/tfx-data-mnistf3ddmh9v/"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tfx-data-mnistf3ddmh9v\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7I9evLOcfIv",
        "outputId": "1ade020f-3cf8-4656-a93f-68a71200d595"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5YPeLPFOXaD"
      },
      "source": [
        "!head {_data_filepath_mnist}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ekcnd7xasZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5a5bfc-9129-408a-8087-15ab62fc8475"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist.tfrecord\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ONIE_hdkPS4"
      },
      "source": [
        "### InteractiveContext\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rh6K5sUf9dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64ce8cd-0940-4c39-ab1d-3f918a3c4c12"
      },
      "source": [
        "context = InteractiveContext()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:InteractiveContext pipeline_root argument not provided: using temporary directory /tmp/tfx-interactive-2020-12-13T04_34_05.733045-ak54b554 as root for pipeline outputs.\n",
            "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at /tmp/tfx-interactive-2020-12-13T04_34_05.733045-ak54b554/metadata.sqlite.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdQWxfsVkzdJ"
      },
      "source": [
        "## Run TFX components interactively\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzX8x9FmYcNU"
      },
      "source": [
        "### Using ImportExampleGen to import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyXjuMt8f-9u"
      },
      "source": [
        "from tfx.components import ImportExampleGen\n",
        "example_gen = ImportExampleGen(input=external_input(_data_root_mnist))\n",
        "context.run(example_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "880KkTAkPeUg"
      },
      "source": [
        "artifact = example_gen.outputs['examples'].get()[0]\n",
        "print(artifact.split_names, artifact.uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4XIXjiCPwzQ"
      },
      "source": [
        "\n",
        "train_uri = os.path.join(example_gen.outputs['examples'].get()[0].uri, 'train')\n",
        "\n",
        "\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gluYjccf-IP"
      },
      "source": [
        "Now that `ExampleGen` has finished ingesting the data, the next step is data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csM6BFhtk5Aa"
      },
      "source": [
        "### StatisticsGen\n",
        "ref:https://www.tensorflow.org/tfx/data_validation/get_started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAscCCYWgA-9"
      },
      "source": [
        "statistics_gen = StatisticsGen(\n",
        "    examples=example_gen.outputs['examples'])\n",
        "context.run(statistics_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLI6cb_5WugZ"
      },
      "source": [
        "After `StatisticsGen` finishes running, we can visualize the outputted statistics. Try playing with the different plots!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLjXy7K6Tp_G"
      },
      "source": [
        "context.show(statistics_gen.outputs['statistics'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLKLTO9Nk60p"
      },
      "source": [
        "### SchemaGen\n",
        "ref: https://www.tensorflow.org/tfx/data_validation/get_started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQvZ6hsiQ_J"
      },
      "source": [
        "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'],infer_feature_shape=False)\n",
        "context.run(schema_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec9vqDXpXeMb"
      },
      "source": [
        "context.show(schema_gen.outputs['schema'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZWWdbA-m7zp"
      },
      "source": [
        "the SchemaGen documentation:\n",
        "https://www.tensorflow.org/tfx/guide/schemagen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1qcUuO9k9f8"
      },
      "source": [
        "### ExampleValidator\n",
        "https://www.tensorflow.org/tfx/data_validation/get_started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRlRUuGgiXks"
      },
      "source": [
        "example_validator = ExampleValidator(\n",
        "    statistics=statistics_gen.outputs['statistics'],\n",
        "    schema=schema_gen.outputs['schema'])\n",
        "context.run(example_validator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "855mrHgJcoer"
      },
      "source": [
        "After `ExampleValidator` finishes running, we can visualize the anomalies as a table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDyAAozQcrk3"
      },
      "source": [
        "context.show(example_validator.outputs['anomalies'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znMoJj60ybZx"
      },
      "source": [
        "In the anomalies table, we can see that there are no anomalies. This is what we'd expect, since this the first dataset that we've analyzed and the schema is tailored to it. You should review this schema -- anything unexpected means an anomaly in the data. Once reviewed, the schema can be used to guard future data, and anomalies produced here can be used to debug model performance, understand how your data evolves over time, and identify data errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPViEz5RlA36"
      },
      "source": [
        "### Transform\n",
        "* https://www.tensorflow.org/tfx/transform/get_started\n",
        "\n",
        "* https://www.tensorflow.org/tfx/tutorials/transform/simple\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuNSiUKb4YJf"
      },
      "source": [
        "_mnist_constants_module_file = 'mnist_constants.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPjhXuIF4YJh"
      },
      "source": [
        "%%writefile {_mnist_constants_module_file}\n",
        "\n",
        "# Categorical features are assumed to each have a maximum value in the dataset.\n",
        "MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
        "\n",
        "CATEGORICAL_FEATURE_KEYS = [\n",
        "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
        "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
        "    'dropoff_community_area'\n",
        "]\n",
        "\n",
        "DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
        "\n",
        "# Number of buckets used by tf.transform for encoding each feature.\n",
        "FEATURE_BUCKET_COUNT = 10\n",
        "\n",
        "BUCKET_FEATURE_KEYS = [\n",
        "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
        "    'dropoff_longitude'\n",
        "]\n",
        "\n",
        "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
        "VOCAB_SIZE = 1000\n",
        "\n",
        "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
        "OOV_SIZE = 10\n",
        "\n",
        "VOCAB_FEATURE_KEYS = [\n",
        "    'payment_type',\n",
        "    'company',\n",
        "]\n",
        "\n",
        "# Keys\n",
        "LABEL_KEY = 'tips'\n",
        "FARE_KEY = 'fare'\n",
        "\n",
        "def transformed_name(key):\n",
        "  return key + '_xf'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj2Ax5z4YJl"
      },
      "source": [
        "Next, we write a `preprocessing_fn` that takes in raw data as input, and returns transformed features that our model can train on:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AJ9hBs94YJm"
      },
      "source": [
        "_mnist_transform_module_file = 'mnist_transform.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYmxxx9A4YJn"
      },
      "source": [
        "%%writefile {_mnist_transform_module_file}\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "import mnist_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = mnist_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = mnist_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = mnist_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = mnist_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = mnist_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = mnist_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = mnist_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_FARE_KEY = mnist_constants.FARE_KEY\n",
        "_LABEL_KEY = mnist_constants.LABEL_KEY\n",
        "_transformed_name = mnist_constants.transformed_name\n",
        "\n",
        "\n",
        "def preprocessing_fn(inputs):\n",
        "  \"\"\"tf.transform's callback function for preprocessing inputs.\n",
        "  Args:\n",
        "    inputs: map from feature keys to raw not-yet-transformed features.\n",
        "  Returns:\n",
        "    Map from string feature key to transformed feature operations.\n",
        "  \"\"\"\n",
        "  outputs = {}\n",
        "  for key in _DENSE_FLOAT_FEATURE_KEYS:\n",
        "    # Preserve this feature as a dense float, setting nan's to the mean.\n",
        "    outputs[_transformed_name(key)] = tft.scale_to_z_score(\n",
        "        _fill_in_missing(inputs[key]))\n",
        "\n",
        "  for key in _VOCAB_FEATURE_KEYS:\n",
        "    # Build a vocabulary for this feature.\n",
        "    outputs[_transformed_name(key)] = tft.compute_and_apply_vocabulary(\n",
        "        _fill_in_missing(inputs[key]),\n",
        "        top_k=_VOCAB_SIZE,\n",
        "        num_oov_buckets=_OOV_SIZE)\n",
        "\n",
        "  for key in _BUCKET_FEATURE_KEYS:\n",
        "    outputs[_transformed_name(key)] = tft.bucketize(\n",
        "        _fill_in_missing(inputs[key]), _FEATURE_BUCKET_COUNT)\n",
        "\n",
        "  for key in _CATEGORICAL_FEATURE_KEYS:\n",
        "    outputs[_transformed_name(key)] = _fill_in_missing(inputs[key])\n",
        "\n",
        "  # Was this passenger a big tipper?\n",
        "  mnist_fare = _fill_in_missing(inputs[_FARE_KEY])\n",
        "  tips = _fill_in_missing(inputs[_LABEL_KEY])\n",
        "  outputs[_transformed_name(_LABEL_KEY)] = tf.where(\n",
        "      tf.math.is_nan(mnist_fare),\n",
        "      tf.cast(tf.zeros_like(mnist_fare), tf.int64),\n",
        "      # Test if the tip was > 20% of the fare.\n",
        "      tf.cast(\n",
        "          tf.greater(tips, tf.multiply(mnist_fare, tf.constant(0.2))), tf.int64))\n",
        "\n",
        "  return outputs\n",
        "\n",
        "\n",
        "def _fill_in_missing(x):\n",
        "  \"\"\"Replace missing values in a SparseTensor.\n",
        "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
        "  Args:\n",
        "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
        "      in the second dimension.\n",
        "  Returns:\n",
        "    A rank 1 tensor where missing values of `x` have been filled in.\n",
        "  \"\"\"\n",
        "  default_value = '' if x.dtype == tf.string else 0\n",
        "  return tf.squeeze(\n",
        "      tf.sparse.to_dense(\n",
        "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
        "          default_value),\n",
        "      axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgbmZr3sgbWW"
      },
      "source": [
        "Now, we pass in this feature engineering code to the `Transform` component and run it to transform your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfhth_GiZI9"
      },
      "source": [
        "transform = Transform(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    module_file=os.path.abspath(_mnist_transform_module_file))\n",
        "context.run(transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwAwb4rARRQ2"
      },
      "source": [
        "Let's examine the output artifacts of `Transform`. This component produces two types of outputs:\n",
        "\n",
        "* `transform_graph` is the graph that can perform the preprocessing operations (this graph will be included in the serving and evaluation models).\n",
        "* `transformed_examples` represents the preprocessed training and evaluation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SClrAaEGR1O5"
      },
      "source": [
        "transform.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyFkBd9AR1sy"
      },
      "source": [
        "Take a peek at the `transform_graph` artifact.  It points to a directory containing three subdirectories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tRw4DneR3i7"
      },
      "source": [
        "train_uri = transform.outputs['transform_graph'].get()[0].uri\n",
        "os.listdir(train_uri)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqV54CIR6Pu"
      },
      "source": [
        "The `transformed_metadata` subdirectory contains the schema of the preprocessed data. The `transform_fn` subdirectory contains the actual preprocessing graph. The `metadata` subdirectory contains the schema of the original data.\n",
        "\n",
        "We can also take a look at the first three transformed examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwbW2zPKR_S4"
      },
      "source": [
        "# Get the URI of the output artifact representing the transformed examples, which is a directory\n",
        "train_uri = os.path.join(transform.outputs['transformed_examples'].get()[0].uri, 'train')\n",
        "\n",
        "# Get the list of files in this directory (all compressed TFRecord files)\n",
        "tfrecord_filenames = [os.path.join(train_uri, name)\n",
        "                      for name in os.listdir(train_uri)]\n",
        "\n",
        "# Create a `TFRecordDataset` to read these files\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
        "\n",
        "# Iterate over the first 3 records and decode them.\n",
        "for tfrecord in dataset.take(3):\n",
        "  serialized_example = tfrecord.numpy()\n",
        "  example = tf.train.Example()\n",
        "  example.ParseFromString(serialized_example)\n",
        "  pp.pprint(example)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_b_V6eN4f69"
      },
      "source": [
        "After the `Transform` component has transformed your data into features, and the next step is to train a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBJFtnl6lCg9"
      },
      "source": [
        "### Trainer\n",
        "The `Trainer` component will train a model that you define in TensorFlow. Default Trainer support Estimator API, to use Keras API, you need to specify [Generic Trainer](https://github.com/tensorflow/community/blob/master/rfcs/20200117-tfx-generic-trainer.md) by setup `custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor)` in Trainer's contructor.\n",
        "\n",
        "`Trainer` takes as input the schema from `SchemaGen`, the transformed data and graph from `Transform`, training parameters, as well as a module that contains user-defined model code.\n",
        "\n",
        "Let's see an example of user-defined model code below (for an introduction to the TensorFlow Keras APIs, [see the tutorial](https://www.tensorflow.org/guide/keras)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1376oq04YJt"
      },
      "source": [
        "_mnist_trainer_module_file = 'mnist_trainer.py'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf9UuNng4YJu"
      },
      "source": [
        "%%writefile {_mnist_trainer_module_file}\n",
        "\n",
        "from typing import List, Text\n",
        "\n",
        "import os\n",
        "import absl\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow_transform as tft\n",
        "\n",
        "from tfx.components.trainer.executor import TrainerFnArgs\n",
        "from tfx.components.trainer.fn_args_utils import DataAccessor\n",
        "from tfx_bsl.tfxio import dataset_options\n",
        "\n",
        "import mnist_constants\n",
        "\n",
        "_DENSE_FLOAT_FEATURE_KEYS = mnist_constants.DENSE_FLOAT_FEATURE_KEYS\n",
        "_VOCAB_FEATURE_KEYS = mnist_constants.VOCAB_FEATURE_KEYS\n",
        "_VOCAB_SIZE = mnist_constants.VOCAB_SIZE\n",
        "_OOV_SIZE = mnist_constants.OOV_SIZE\n",
        "_FEATURE_BUCKET_COUNT = mnist_constants.FEATURE_BUCKET_COUNT\n",
        "_BUCKET_FEATURE_KEYS = mnist_constants.BUCKET_FEATURE_KEYS\n",
        "_CATEGORICAL_FEATURE_KEYS = mnist_constants.CATEGORICAL_FEATURE_KEYS\n",
        "_MAX_CATEGORICAL_FEATURE_VALUES = mnist_constants.MAX_CATEGORICAL_FEATURE_VALUES\n",
        "_LABEL_KEY = mnist_constants.LABEL_KEY\n",
        "_transformed_name = mnist_constants.transformed_name\n",
        "\n",
        "\n",
        "def _transformed_names(keys):\n",
        "  return [_transformed_name(key) for key in keys]\n",
        "\n",
        "\n",
        "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
        "  \"\"\"Returns a function that parses a serialized tf.Example and applies TFT.\"\"\"\n",
        "\n",
        "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
        "\n",
        "  @tf.function\n",
        "  def serve_tf_examples_fn(serialized_tf_examples):\n",
        "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
        "    feature_spec = tf_transform_output.raw_feature_spec()\n",
        "    feature_spec.pop(_LABEL_KEY)\n",
        "    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
        "    transformed_features = model.tft_layer(parsed_features)\n",
        "    return model(transformed_features)\n",
        "\n",
        "  return serve_tf_examples_fn\n",
        "\n",
        "\n",
        "def _input_fn(file_pattern: List[Text],\n",
        "              data_accessor: DataAccessor,\n",
        "              tf_transform_output: tft.TFTransformOutput,\n",
        "              batch_size: int = 200) -> tf.data.Dataset:\n",
        "  \"\"\"Generates features and label for tuning/training.\n",
        "\n",
        "  Args:\n",
        "    file_pattern: List of paths or patterns of input tfrecord files.\n",
        "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
        "    tf_transform_output: A TFTransformOutput.\n",
        "    batch_size: representing the number of consecutive elements of returned\n",
        "      dataset to combine in a single batch\n",
        "\n",
        "  Returns:\n",
        "    A dataset that contains (features, indices) tuple where features is a\n",
        "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
        "  \"\"\"\n",
        "  return data_accessor.tf_dataset_factory(\n",
        "      file_pattern,\n",
        "      dataset_options.TensorFlowDatasetOptions(\n",
        "          batch_size=batch_size, label_key=_transformed_name(_LABEL_KEY)),\n",
        "      tf_transform_output.transformed_metadata.schema)\n",
        "\n",
        "\n",
        "def _build_keras_model(hidden_units: List[int] = None) -> tf.keras.Model:\n",
        "  \"\"\"Creates a DNN Keras model for classifying mnist data.\n",
        "\n",
        "  Args:\n",
        "    hidden_units: [int], the layer sizes of the DNN (input layer first).\n",
        "\n",
        "  Returns:\n",
        "    A keras Model.\n",
        "  \"\"\"\n",
        "  real_valued_columns = [\n",
        "      tf.feature_column.numeric_column(key, shape=())\n",
        "      for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n",
        "  ]\n",
        "  categorical_columns = [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
        "      for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(\n",
        "          key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
        "      for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n",
        "  ]\n",
        "  categorical_columns += [\n",
        "      tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
        "          key,\n",
        "          num_buckets=num_buckets,\n",
        "          default_value=0) for key, num_buckets in zip(\n",
        "              _transformed_names(_CATEGORICAL_FEATURE_KEYS),\n",
        "              _MAX_CATEGORICAL_FEATURE_VALUES)\n",
        "  ]\n",
        "  indicator_column = [\n",
        "      tf.feature_column.indicator_column(categorical_column)\n",
        "      for categorical_column in categorical_columns\n",
        "  ]\n",
        "\n",
        "  model = _wide_and_deep_classifier(\n",
        "      # TODO(b/139668410) replace with premade wide_and_deep keras model\n",
        "      wide_columns=indicator_column,\n",
        "      deep_columns=real_valued_columns,\n",
        "      dnn_hidden_units=hidden_units or [100, 70, 50, 25])\n",
        "  return model\n",
        "\n",
        "\n",
        "def _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units):\n",
        "  \"\"\"Build a simple keras wide and deep model.\n",
        "\n",
        "  Args:\n",
        "    wide_columns: Feature columns wrapped in indicator_column for wide (linear)\n",
        "      part of the model.\n",
        "    deep_columns: Feature columns for deep part of the model.\n",
        "    dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n",
        "\n",
        "  Returns:\n",
        "    A Wide and Deep Keras model\n",
        "  \"\"\"\n",
        "  # Following values are hard coded for simplicity in this example,\n",
        "  # However prefarably they should be passsed in as hparams.\n",
        "\n",
        "  # Keras needs the feature definitions at compile time.\n",
        "  # TODO(b/139081439): Automate generation of input layers from FeatureColumn.\n",
        "  input_layers = {\n",
        "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n",
        "      for colname in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n",
        "  }\n",
        "  input_layers.update({\n",
        "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n",
        "      for colname in _transformed_names(_VOCAB_FEATURE_KEYS)\n",
        "  })\n",
        "  input_layers.update({\n",
        "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n",
        "      for colname in _transformed_names(_BUCKET_FEATURE_KEYS)\n",
        "  })\n",
        "  input_layers.update({\n",
        "      colname: tf.keras.layers.Input(name=colname, shape=(), dtype='int32')\n",
        "      for colname in _transformed_names(_CATEGORICAL_FEATURE_KEYS)\n",
        "  })\n",
        "\n",
        "  # TODO(b/161952382): Replace with Keras preprocessing layers.\n",
        "  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n",
        "  for numnodes in dnn_hidden_units:\n",
        "    deep = tf.keras.layers.Dense(numnodes)(deep)\n",
        "  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n",
        "\n",
        "  output = tf.keras.layers.Dense(\n",
        "      1, activation='sigmoid')(\n",
        "          tf.keras.layers.concatenate([deep, wide]))\n",
        "\n",
        "  model = tf.keras.Model(input_layers, output)\n",
        "  model.compile(\n",
        "      loss='binary_crossentropy',\n",
        "      optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "  model.summary(print_fn=absl.logging.info)\n",
        "  return model\n",
        "\n",
        "\n",
        "# TFX Trainer will call this function.\n",
        "def run_fn(fn_args: TrainerFnArgs):\n",
        "  \"\"\"Train the model based on given args.\n",
        "\n",
        "  Args:\n",
        "    fn_args: Holds args used to train the model as name/value pairs.\n",
        "  \"\"\"\n",
        "  # Number of nodes in the first layer of the DNN\n",
        "  first_dnn_layer_size = 100\n",
        "  num_dnn_layers = 4\n",
        "  dnn_decay_factor = 0.7\n",
        "\n",
        "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
        "\n",
        "  train_dataset = _input_fn(fn_args.train_files, fn_args.data_accessor, \n",
        "                            tf_transform_output, 40)\n",
        "  eval_dataset = _input_fn(fn_args.eval_files, fn_args.data_accessor, \n",
        "                           tf_transform_output, 40)\n",
        "\n",
        "  model = _build_keras_model(\n",
        "      # Construct layers sizes with exponetial decay\n",
        "      hidden_units=[\n",
        "          max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
        "          for i in range(num_dnn_layers)\n",
        "      ])\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=fn_args.model_run_dir, update_freq='batch')\n",
        "  model.fit(\n",
        "      train_dataset,\n",
        "      steps_per_epoch=fn_args.train_steps,\n",
        "      validation_data=eval_dataset,\n",
        "      validation_steps=fn_args.eval_steps,\n",
        "      callbacks=[tensorboard_callback])\n",
        "\n",
        "  signatures = {\n",
        "      'serving_default':\n",
        "          _get_serve_tf_examples_fn(model,\n",
        "                                    tf_transform_output).get_concrete_function(\n",
        "                                        tf.TensorSpec(\n",
        "                                            shape=[None],\n",
        "                                            dtype=tf.string,\n",
        "                                            name='examples')),\n",
        "  }\n",
        "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY4yTRaX4YJx"
      },
      "source": [
        "Now, we pass in this model code to the `Trainer` component and run it to train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "429-vvCWibO0"
      },
      "source": [
        "trainer = Trainer(\n",
        "    module_file=os.path.abspath(_mnist_trainer_module_file),\n",
        "    custom_executor_spec=executor_spec.ExecutorClassSpec(GenericExecutor),\n",
        "    examples=transform.outputs['transformed_examples'],\n",
        "    transform_graph=transform.outputs['transform_graph'],\n",
        "    schema=schema_gen.outputs['schema'],\n",
        "    train_args=trainer_pb2.TrainArgs(num_steps=10000),\n",
        "    eval_args=trainer_pb2.EvalArgs(num_steps=5000))\n",
        "context.run(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cql1G35StJp"
      },
      "source": [
        "#### Analyze Training with TensorBoard\n",
        "Take a peek at the trainer artifact. It points to a directory containing the model subdirectories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXe62WE0S0Ek"
      },
      "source": [
        "model_artifact_dir = trainer.outputs['model'].get()[0].uri\n",
        "pp.pprint(os.listdir(model_artifact_dir))\n",
        "model_dir = os.path.join(model_artifact_dir, 'serving_model_dir')\n",
        "pp.pprint(os.listdir(model_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfjOmSro6Q3Y"
      },
      "source": [
        "Optionally, we can connect TensorBoard to the Trainer to analyze our model's training curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-APzqz2NeAyj"
      },
      "source": [
        "model_run_artifact_dir = trainer.outputs['model_run'].get()[0].uri\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {model_run_artifact_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmPftrv0lEQy"
      },
      "source": [
        "### Evaluator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVhfzzh9PDEx"
      },
      "source": [
        "eval_config = tfma.EvalConfig(\n",
        "    model_specs=[\n",
        "        # This assumes a serving model with signature 'serving_default'. If\n",
        "        # using estimator based EvalSavedModel, add signature_name: 'eval' and \n",
        "        # remove the label_key.\n",
        "        tfma.ModelSpec(label_key='tips')\n",
        "    ],\n",
        "    metrics_specs=[\n",
        "        tfma.MetricsSpec(\n",
        "            # The metrics added here are in addition to those saved with the\n",
        "            # model (assuming either a keras model or EvalSavedModel is used).\n",
        "            # Any metrics added into the saved model (for example using\n",
        "            # model.compile(..., metrics=[...]), etc) will be computed\n",
        "            # automatically.\n",
        "            # To add validation thresholds for metrics saved with the model,\n",
        "            # add them keyed by metric name to the thresholds map.\n",
        "            metrics=[\n",
        "                tfma.MetricConfig(class_name='ExampleCount'),\n",
        "                tfma.MetricConfig(class_name='BinaryAccuracy',\n",
        "                  threshold=tfma.MetricThreshold(\n",
        "                      value_threshold=tfma.GenericValueThreshold(\n",
        "                          lower_bound={'value': 0.5}),\n",
        "                      change_threshold=tfma.GenericChangeThreshold(\n",
        "                          direction=tfma.MetricDirection.HIGHER_IS_BETTER,\n",
        "                          absolute={'value': -1e-10})))\n",
        "            ]\n",
        "        )\n",
        "    ],\n",
        "    slicing_specs=[\n",
        "        # An empty slice spec means the overall slice, i.e. the whole dataset.\n",
        "        tfma.SlicingSpec(),\n",
        "        # Data can be sliced along a feature column. In this case, data is\n",
        "        # sliced along feature column trip_start_hour.\n",
        "        tfma.SlicingSpec(feature_keys=['trip_start_hour'])\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBdKH1F8JuT"
      },
      "source": [
        "Next, we give this configuration to `Evaluator` and run it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjcx8g6mihSt"
      },
      "source": [
        "# Use TFMA to compute a evaluation statistics over features of a model and\n",
        "# validate them against a baseline.\n",
        "\n",
        "# The model resolver is only required if performing model validation in addition\n",
        "# to evaluation. In this case we validate against the latest blessed model. If\n",
        "# no model has been blessed before (as in this case) the evaluator will make our\n",
        "# candidate the first blessed model.\n",
        "model_resolver = ResolverNode(\n",
        "      instance_name='latest_blessed_model_resolver',\n",
        "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
        "      model=Channel(type=Model),\n",
        "      model_blessing=Channel(type=ModelBlessing))\n",
        "context.run(model_resolver)\n",
        "\n",
        "evaluator = Evaluator(\n",
        "    examples=example_gen.outputs['examples'],\n",
        "    model=trainer.outputs['model'],\n",
        "    baseline_model=model_resolver.outputs['model'],\n",
        "    # Change threshold will be ignored if there is no baseline (first run).\n",
        "    eval_config=eval_config)\n",
        "context.run(evaluator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCVkBusS_8g"
      },
      "source": [
        "Now let's examine the output artifacts of `Evaluator`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4GghePOTJxL"
      },
      "source": [
        "evaluator.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TMskWe9LL0"
      },
      "source": [
        "Using the `evaluation` output we can show the default visualization of global metrics on the entire evaluation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U729j5X5QQUQ"
      },
      "source": [
        "context.show(evaluator.outputs['evaluation'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-tI4p6m-OAn"
      },
      "source": [
        "To see the visualization for sliced evaluation metrics, we can directly call the TensorFlow Model Analysis library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyis6iy0HLdi"
      },
      "source": [
        "import tensorflow_model_analysis as tfma\n",
        "\n",
        "# Get the TFMA output result path and load the result.\n",
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "tfma_result = tfma.load_eval_result(PATH_TO_RESULT)\n",
        "\n",
        "# Show data sliced along feature column trip_start_hour.\n",
        "tfma.view.render_slicing_metrics(\n",
        "    tfma_result, slicing_column='trip_start_hour')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uvYrUf2-r_6"
      },
      "source": [
        "This visualization shows the same metrics, but computed at every feature value of `trip_start_hour` instead of on the entire evaluation set.\n",
        "\n",
        "TensorFlow Model Analysis supports many other visualizations, such as Fairness Indicators and plotting a time series of model performance. To learn more, see [the tutorial](https://www.tensorflow.org/tfx/tutorials/model_analysis/tfma_basic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEotnkxEswUb"
      },
      "source": [
        "Since we added thresholds to our config, validation output is also available. The precence of a `blessing` artifact indicates that our model passed validation. Since this is the first validation being performed the candidate is automatically blessed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZmiRtg6TKtR"
      },
      "source": [
        "blessing_uri = evaluator.outputs.blessing.get()[0].uri\n",
        "!ls -l {blessing_uri}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1tFkOVSBa0"
      },
      "source": [
        "Now can also verify the success by loading the validation result record:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxa5G08bSJ8a"
      },
      "source": [
        "PATH_TO_RESULT = evaluator.outputs['evaluation'].get()[0].uri\n",
        "print(tfma.load_validation_result(PATH_TO_RESULT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8DYekCZlHfj"
      },
      "source": [
        "### Pusher\n",
        "The `Pusher` component is usually at the end of a TFX pipeline. It checks whether a model has passed validation, and if so, exports the model to `_serving_model_dir`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHcvRryTifWv"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r45nQ69eikc9"
      },
      "source": [
        "pusher = Pusher(  model=trainer.outputs['model'],\n",
        "    model_blessing=evaluator.outputs['blessing'],\n",
        "    push_destination=pusher_pb2.PushDestination(\n",
        "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
        "            base_directory=_serving_model_dir_mnist)))\n",
        "context.run(pusher)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctUErBYoTO9I"
      },
      "source": [
        "Let's examine the output artifacts of `Pusher`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRkWo-MzTSss"
      },
      "source": [
        "pusher.outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zyIqWl9TSdG"
      },
      "source": [
        "push_uri = pusher.outputs.model_push.get()[0].uri\n",
        "model = tf.saved_model.load(push_uri)\n",
        "\n",
        "for item in model.signatures.items():\n",
        "  pp.pprint(item)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-YPNUuHANtj"
      },
      "source": [
        "We're finished our tour of built-in TFX components!"
      ]
    }
  ]
}