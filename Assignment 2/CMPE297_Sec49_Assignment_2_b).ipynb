{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " CMPE297_Sec49_Assignment_2_b).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPctb3LzbV3XEexP/NNucRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zjzsu2000/CMPE297_Sec49AdvanceDL/blob/master/Assignment%202/CMPE297_Sec49_Assignment_2_b).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRqJ1beePiPO",
        "colab_type": "text"
      },
      "source": [
        "# CMPE297_Sec49_Assignment_2_b)\n",
        "\n",
        "Low level tensorflow code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taHpNUFWPu2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgPaw5m6P7_y",
        "colab_type": "text"
      },
      "source": [
        "## LinearClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMuTZmfdP5Ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearClassifier:\n",
        "    def __init__(self, num_features=784, num_classes=2, learning_rate=0.01):\n",
        "        self.num_classes = num_classes\n",
        "        self.W = tf.Variable(tf.ones([num_features, num_classes]), name='weight')\n",
        "        self.b = tf.Variable(tf.zeros([num_classes]), name='bias')\n",
        "        self.optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "    def calculate_y(self, x):\n",
        "        y = tf.nn.softmax(tf.matmul(x, self.W) + self.b)\n",
        "        return y\n",
        "\n",
        "    def cost(self, y_pred, y_true):\n",
        "        y_true = tf.one_hot(y_true, depth=self.num_classes)\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "        return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
        "\n",
        "    def iteration(self, x, y):\n",
        "        with tf.GradientTape() as g:\n",
        "            pred = self.calculate_y(x)\n",
        "            loss = self.cost(pred, y)\n",
        "        gradients = g.gradient(loss, [self.W, self.b])\n",
        "\n",
        "        self.optimizer.apply_gradients(zip(gradients, [self.W, self.b]))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzmhUIQmQAnl",
        "colab_type": "text"
      },
      "source": [
        "## SVMClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNKS5S2FQEDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SVMClassifier:\n",
        "    def __init__(self, num_features=784, num_classes=2, reg_strength=10000, learning_rate=0.01):\n",
        "        self.num_classes = num_classes\n",
        "        self.num_features = num_features\n",
        "        self.W = tf.Variable(tf.ones([num_features, num_features]), name='weight')\n",
        "        self.b = tf.Variable(tf.zeros([num_classes]), name='bias')\n",
        "        self.reg_strength = reg_strength\n",
        "        self.optimizer = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "    def cost(self, x, y):\n",
        "        distances = 1 - y * (tf.matmul(x, self.W))\n",
        "        distances[distances < 0] = 0\n",
        "        hinge_loss = self.reg_strength * (tf.reduce_sum(distances) / self.num_features)\n",
        "        cost = 1 / 2 * tf.matmul(self.W, self.W) + hinge_loss\n",
        "        return cost\n",
        "\n",
        "    def iteration(self, x, y):\n",
        "        with tf.GradientTape() as g:\n",
        "            cost = self.cost(x, y)\n",
        "\n",
        "        gradients = g.gradient(cost, self.W)\n",
        "\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.W))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfSRm6t6QG2X",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrTV8EqcQJXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "\n",
        "\n",
        "class DenseLayer(keras.layers.Layer):\n",
        "    def __init__(self, units, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)         \n",
        "\n",
        "    def build(self, batch_input_shape):\n",
        "        self.kernel = self.add_weight(name=\"kernel\", shape=[batch_input_shape[-1], self.units], initializer=\"glorot_normal\")\n",
        "        self.bias = self.add_weight(name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
        "        super().build(batch_input_shape)\n",
        "\n",
        "    def call(self, X):\n",
        "        return self.activation(X @ self.kernel + self.bias)\n",
        "\n",
        "    def compute_output_shape(self, batch_input_shape):\n",
        "        return tf.TensorShape(batch_input_shape.as_list()[:-1] + [self.units])\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        return {**base_config, \"units\":self.units, \"activation\":keras.activations.serialize(self.activation)}\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, layer1, layer2, layer3, layer4):\n",
        "        self.layer1 = layer1\n",
        "        self.layer2 = layer2        \n",
        "        self.weight1 = self.layer1.kernel\n",
        "        self.weight2 = self.layer2.kernel\n",
        "\n",
        "        self.layer3 = layer3\n",
        "        self.layer4 = layer4\n",
        "        self.weight3 = self.layer3.kernel\n",
        "        self.weight4 = self.layer4.kernel\n",
        "\n",
        "    def back_propagation(self, x, y, iterations):\n",
        "        for iteration in range(iterations):\n",
        "            output1 = tf.sigmoid(tf.matmul(x, self.weight1))\n",
        "            output2 = tf.sigmoid(tf.matmul(output1, self.weight2))\n",
        "            output3 = tf.sigmoid(tf.matmul(output2, self.weight3))\n",
        "            output4 = tf.sigmoid(tf.matmul(output3, self.weight4))\n",
        "\n",
        "            layer4_error = y - output4\n",
        "            layer4_delta = layer4_error * derivative(output4)\n",
        "            layer3_error = tf.matmul(layer4_delta, tf.transpose(self.weight4))\n",
        "            layer3_delta = layer3_error * derivative(output3)\n",
        "            layer2_error = tf.matmul(layer3_delta, tf.transpose(self.weight3))\n",
        "            layer2_delta = layer2_error * derivative(output2)\n",
        "            layer1_error = tf.matmul(layer2_delta, tf.transpose(self.weight2))\n",
        "            layer1_delta = layer1_error * derivative(output1)\n",
        "\n",
        "            layer1_offset = tf.matmul(tf.transpose(x), layer1_delta)\n",
        "            layer2_offset = tf.matmul(tf.transpose(output1), layer2_delta)\n",
        "            layer3_offset = tf.matmul(tf.transpose(output2), layer3_delta)\n",
        "            layer4_offset = tf.matmul(tf.transpose(output3), layer4_delta)\n",
        "\n",
        "            self.weight1 += layer1_offset\n",
        "            self.weight2 += layer2_offset\n",
        "            self.weight3 += layer3_offset\n",
        "            self.weight4 += layer4_offset\n",
        "\n",
        "    # def backprop(self, x, y, iterations):\n",
        "    #     for iteration in range(iterations):\n",
        "    #         output1 = tf.sigmoid(tf.matmul(x, self.layer1.weights))\n",
        "    #         output2 = tf.sigmoid(tf.matmul(output1, self.layer2.weights))\n",
        "    #\n",
        "    #         layer2_error = y - output2\n",
        "    #         layer2_delta = layer2_error * derivative(output2)\n",
        "    #\n",
        "    #         layer1_error = tf.matmul(layer2_delta, tf.transpose(self.weight2))\n",
        "    #         layer1_delta = layer1_error * derivative(output1)\n",
        "    #\n",
        "    #         layer1_offset = tf.matmul(tf.transpose(x), layer1_delta)\n",
        "    #         layer2_offset = tf.matmul(tf.transpose(output1), layer2_delta)\n",
        "    #\n",
        "    #         self.weight1 += layer1_offset\n",
        "    #         self.weight2 += layer2_offset\n",
        "\n",
        "\n",
        "def derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    layer1 = DenseLayer(128)\n",
        "    layer1.build((28,28,3))\n",
        "    layer2 = DenseLayer(64)\n",
        "    layer2.build((28,28,3))\n",
        "    layer3 = DenseLayer(64)\n",
        "    layer3.build((28,28,3))\n",
        "    layer4 = DenseLayer(64)\n",
        "    layer4.build((28,28,3))\n",
        "    neura_network = NeuralNetwork(layer1, layer2, layer3, layer4)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}